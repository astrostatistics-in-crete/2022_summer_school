{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "\"**Tuning**\" refers to the procedure of selecting the best hyper-parameters for a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration (mean CV score = 0.867):\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 6, 'RFC__n_estimators': 100}\n",
      "CPU times: user 700 ms, sys: 79.2 ms, total: 779 ms\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration (mean CV score = %0.3f):\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the learning method was wrong all along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The CV method selects the model returning the best average score: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment many times, with different data, which would be the expectation on the best score?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection $-$ the right way\n",
    "\n",
    "Let's look at the general case of **Model Selection**, i.e. select a variety of models and report their performance.\n",
    "\n",
    "The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$as we have seen $-$ a model can be seen as a configuration which might \"switch\" _on_ or _off_ a specific algorithm.\n",
    "\n",
    "For the sake of simplicity, in this section we will only try to select among different **classifiers** (we forget about all the other processing).\n",
    "\n",
    "<u>Unbiased estimations</u>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ Use a hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ Enter **Nested Cross Validation (NCV)**!\n",
    "\n",
    "<u>How NCV works</u>\n",
    "\n",
    "In the basic CV, we didn't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CV!\n",
    "\n",
    "Now, we can think the NCV as a whole as _the_ **learning method**.\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model and the performance estimations on the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_learning_method.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Important Notice</u>\n",
    "\n",
    "This sounds overinterpreted, but it's not!\n",
    "\n",
    "Notice how the model (configuration) selected by each CV can be different!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links before we start:\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to select among models\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 1.0}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.79 | test = 0.90\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 20}), 'scaler__selected_model': ('max', {})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.824 (+/-0.051)\n",
      "\n",
      "CPU times: user 12.5 s, sys: 90.9 ms, total: 12.5 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Configuring the outer CV procedure:\n",
    "cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "outer_models = OrderedDict()\n",
    "# dictionary of best models found at each outer iteration <indexed by outer CV iteration>\n",
    "\n",
    "for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "# outer CV loop\n",
    "# NOTE: We will only use the training set for the NCV, and further split it.\n",
    "#       We want to keep the hold-out set for the final check!\n",
    "    \n",
    "    cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "    \n",
    "    # Splitting outer CV data in train and test:\n",
    "    X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "    y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "    \n",
    "    # > Executing the search (i.e., the inner CV loop):\n",
    "    result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "    # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "    #       inner train and validation sets by GridSearchCV\n",
    "    \n",
    "    # Getting the best performing model from the inner iteration:\n",
    "    best_inner_model = result.best_estimator_\n",
    "    \n",
    "    # > Evaluating model on the test fold\n",
    "    \n",
    "    # Predicting labels on the outer test fold:\n",
    "    yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "    # Scoring the model on test fold:\n",
    "    score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "    \n",
    "    # Storing score result for current [outer CV] fold:\n",
    "    outer_models[str(i)] = OrderedDict({  \n",
    "        'score': score,\n",
    "        'cfg': result.best_params_\n",
    "    })\n",
    "\n",
    "    print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "    print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "# Converting <outer_models> to a dataframe, for better visualization:\n",
    "df_score = pd.DataFrame([outer_model['score'] for key, outer_model in outer_models.items()], columns=['score'])\n",
    "df_cfg   = pd.DataFrame([outer_model['cfg'] for key, outer_model in outer_models.items()])\n",
    "df_outer_models = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "# Summarizing the estimated performance of the model:\n",
    "print()\n",
    "print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "      (np.mean(df_outer_models['score']), np.std(df_outer_models['score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 1.0})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "0  0.809524  (rf, {'n_estimators': 100})   \n",
       "1  0.857143            (svm, {'C': 1.0})   \n",
       "2  0.904762   (rf, {'n_estimators': 20})   \n",
       "3  0.785714            (svm, {'C': 0.1})   \n",
       "4  0.761905            (svm, {'C': 0.1})   \n",
       "\n",
       "                          scaler__selected_model  \n",
       "0   (std, {'with_mean': True, 'with_std': True})  \n",
       "1  (std, {'with_mean': True, 'with_std': False})  \n",
       "2                                      (max, {})  \n",
       "3   (std, {'with_mean': True, 'with_std': True})  \n",
       "4   (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  classifier__selected_model scaler__selected_model\n",
       "2  0.904762  (rf, {'n_estimators': 20})              (max, {})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('rf', {'n_estimators': 20}) ('max', {})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_models)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_models[df_outer_models['score'] == df_outer_models['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining on all training data using:\n",
      "\tScaler: StandardScaler()\n",
      "\tClassifier: RandomForestClassifier(n_estimators=20)\n",
      "\t\t {'n_estimators': 20}\n",
      "{'model_id': 43, 'rank': 1, 'cost': 0.0714285714285714, 'ensemble_weight': 1.0, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f35966b2910>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f35966b2be0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f35966b2eb0>, 'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
      "              early_stopping=True, hidden_layer_sizes=(112, 112),\n",
      "              learning_rate_init=0.00020139694272470796, max_iter=32,\n",
      "              n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}\n"
     ]
    }
   ],
   "source": [
    "# Retraining best configuration on all training data:\n",
    "\n",
    "cls_params    = (df_best['classifier__selected_model'].values[0])[1]\n",
    "scaler_params = (df_best['scaler__selected_model'].values[0])[1]\n",
    "\n",
    "# Replace with best configuration scaler and classifier printed above:\n",
    "#\n",
    "# LinearSVC() or\n",
    "# RandomForestClassifier()\n",
    "#\n",
    "# StandardScaler() or\n",
    "# MaxAbsScaler()\n",
    "#\n",
    "scaler = StandardScaler(**scaler_params)\n",
    "cls    = RandomForestClassifier(**cls_params)\n",
    "\n",
    "print('Retraining on all training data using:')\n",
    "print('\\tScaler:', scaler)\n",
    "print('\\tClassifier:', cls)\n",
    "print('\\t\\t', cls_params)\n",
    "\n",
    "model_NCV = Pipeline([('scaler', scaler), ('cls', cls)])\n",
    "print(model)\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 s, sys: 1.05 s, total: 45.8 s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, per_run_time_limit=12,\n",
       "                      time_left_for_this_task=120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 75e0a400-e8c7-11ec-a632-9c5c8e15fdc0\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.928571\n",
      "  Number of target algorithm runs: 42\n",
      "  Number of successful target algorithm runs: 42\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selected model ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{43: {'model_id': 43,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0714285714285714,\n",
       "  'ensemble_weight': 1.0,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f35966b2910>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f35966b2be0>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f35966b2eb0>,\n",
       "  'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
       "                early_stopping=True, hidden_layer_sizes=(112, 112),\n",
       "                learning_rate_init=0.00020139694272470796, max_iter=32,\n",
       "                n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"data_preprocessing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0,\n",
       "                                                    transformers=[('numerical_transformer',\n",
       "                                                                   NumericalPreprocessingPipeline(config=Configuration:\n",
       "   imputation:strategy, Value: 'median'\n",
       "   rescaling:__choice__, Value: 'standardize'\n",
       " , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Num...\n",
       "                       'categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "                       'numerical_transformer:imputation:strategy': 'median',\n",
       "                       'numerical_transformer:rescaling:__choice__': 'standardize'},\n",
       "               feat_type={0: 'numerical', 1: 'numerical', 2: 'numerical',\n",
       "                          3: 'numerical', 4: 'numerical', 5: 'numerical',\n",
       "                          6: 'numerical', 7: 'numerical', 8: 'numerical',\n",
       "                          9: 'numerical'},\n",
       "               init_params={}),\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"balancing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'strategy': 'weighting', 'random_state': 1, 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"feature_preprocessor\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    random_state=1),\n",
       " 'new_params': {'degree': 2,\n",
       "  'include_bias': 'True',\n",
       "  'interaction_only': 'False',\n",
       "  'random_state': 1},\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
