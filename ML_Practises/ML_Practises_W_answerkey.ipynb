{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "\"**Tuning**\" refers to the procedure of selecting the best hyper-parameters for a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration (mean CV score = 0.876):\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 6, 'RFC__n_estimators': 100}\n",
      "CPU times: user 746 ms, sys: 114 ms, total: 860 ms\n",
      "Wall time: 7.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration (mean CV score = %0.3f):\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the learning method was wrong all along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The CV method selects the model returning the best average score: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment many times, with different data, which would be the expectation on the best score?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.82%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection $-$ the right way\n",
    "\n",
    "Let's look at the general case of **Model Selection**, i.e. select a variety of models and report their performance.\n",
    "\n",
    "The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$as we have seen $-$ a model can be seen as a configuration which might \"switch\" _on_ or _off_ a specific algorithm.\n",
    "\n",
    "For the sake of simplicity, in this section we will only try to select among different **classifiers** (we forget about all the other processing).\n",
    "\n",
    "<u>Unbiased estimations</u>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ Use a hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ Enter **Nested Cross Validation (NCV)**!\n",
    "\n",
    "<u>How NCV works</u>\n",
    "\n",
    "In the basic CV, we didn't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CV!\n",
    "\n",
    "Now, we can think the NCV as a whole as _the_ **learning method**.\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model and the performance estimations on the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_learning_method.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Important Notice</u>\n",
    "\n",
    "This sounds overinterpreted, but it's not!\n",
    "\n",
    "Notice how the model (configuration) selected by each CV can be different!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links before we start:\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to select among models\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('max', {})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.79 | test = 0.88\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 20}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.819 (+/-0.044)\n",
      "\n",
      "CPU times: user 12.6 s, sys: 102 ms, total: 12.7 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(knn, {'n_neighbors': 3})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=5)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 6})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>(knn, {'n_neighbors': 5})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 3})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "0  0.880952   (qtt, {'output_distribution': 'normal'})   \n",
       "1  0.880952   (qtt, {'output_distribution': 'normal'})   \n",
       "2  0.952381  (qtt, {'output_distribution': 'uniform'})   \n",
       "3  0.785714                                  (max, {})   \n",
       "4  0.761905  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "0               (knn, {'n_neighbors': 3})  \n",
       "1  (gpc, {'kernel': RBF(length_scale=5)})  \n",
       "2               (knn, {'n_neighbors': 6})  \n",
       "3               (knn, {'n_neighbors': 5})  \n",
       "4               (knn, {'n_neighbors': 3})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 6})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "2  0.952381  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "  classifier__selected_model  \n",
       "2  (knn, {'n_neighbors': 6})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('qtt', {'output_distribution': 'uniform'}) ('knn', {'n_neighbors': 6})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.79%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds.\n",
    "\n",
    "**Report the score of the re-trained model on the test set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('max', MaxAbsScaler()),\n",
    "            ('qtt', QuantileTransformer(random_state=0, n_quantiles=10)),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('gpc', GaussianProcessClassifier()),\n",
    "            ('knn', KNeighborsClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'qtt__output_distribution': ['normal', 'uniform'],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'gpc__kernel': [RBF(1.0), RBF(5.0)],\n",
    "            'knn__n_neighbors': randint(3, 20).rvs(size=4),\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.87 | test = 0.83\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 17})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('gpc', {'kernel': RBF(length_scale=1)})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.90\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 18})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'scaler__selected_model': ('max', {}), 'classifier__selected_model': ('knn', {'n_neighbors': 12})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.74\n",
      "\tSelected config: {'scaler__selected_model': ('max', {}), 'classifier__selected_model': ('knn', {'n_neighbors': 18})}\n",
      "\n",
      "\n",
      "Mean test score: 0.833 (+/-0.058)\n",
      "\n",
      "CPU times: user 2min 21s, sys: 1min 5s, total: 3min 27s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 17})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=1)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 18})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>(knn, {'n_neighbors': 12})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738095</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>(knn, {'n_neighbors': 18})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "0  0.833333  (qtt, {'output_distribution': 'uniform'})   \n",
       "1  0.880952   (qtt, {'output_distribution': 'normal'})   \n",
       "2  0.904762  (qtt, {'output_distribution': 'uniform'})   \n",
       "3  0.809524                                  (max, {})   \n",
       "4  0.738095                                  (max, {})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "0              (knn, {'n_neighbors': 17})  \n",
       "1  (gpc, {'kernel': RBF(length_scale=1)})  \n",
       "2              (knn, {'n_neighbors': 18})  \n",
       "3              (knn, {'n_neighbors': 12})  \n",
       "4              (knn, {'n_neighbors': 18})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 18})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "2  0.904762  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "   classifier__selected_model  \n",
       "2  (knn, {'n_neighbors': 18})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('qtt', {'output_distribution': 'uniform'})\n",
      "  ('knn', {'n_neighbors': 18})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.84%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
