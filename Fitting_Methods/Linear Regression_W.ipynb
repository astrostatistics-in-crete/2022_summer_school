{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression and Minimization - Workshop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "In the introduction session, we discussed how to find the best-fit line to data. In this model, we found that the least-squares solution is mathematically identical to minimizing $\\chi^2$:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i=1}^N \\frac{\\left[ y_i - f(x_i) \\right]^2}{\\sigma^2_{y,i}}\n",
    "$$\n",
    "\n",
    "\n",
    "### In this session...\n",
    "\n",
    "we are going to extend beyond linear models, to a model of arbitrary complexity. But first, let's look at the equation above. \n",
    "\n",
    "First, we have the summation: $\\sum_{i=1}^N$. The fact that we are summing over indices implies we have a discreet number of data points. These data are represented by $x_i$ and $y_i$, as well as their uncertainties $\\sigma_{y,i}$. \n",
    "\n",
    "$f(x_i)$ in the equation above is where our model comes in. There is no requirement that $f$ be a linear function, only that it is a _generative model_. A generative model means that our model can \"produce\" mock data. In our case, that means that, for a give input $x_i$, our model provides exactly one model output $y_i$. The $\\chi^2$ equation above allows us statistically compare the model output with the observations.\n",
    "\n",
    "So, to use $\\chi^2$ minimization techniques, all we need to do is write down a function, $f(x)$ that gives us an output to compare with the observed data points. \n",
    "\n",
    "\n",
    "### The problem: fitting a spectral line\n",
    "\n",
    "Spectroscopy, in which we break up the light from an object (star, galaxy, planet, etc.) into its separate wavelengths, is currently, and has been over the past century, a driving technique in astronomy. It allows us to measure the elemental abundances of stars and the star formation histories of galaxies, to give just two examples. It also allows us to measure the properties of a white dwarf, specifically the temperature and surface gravity. \n",
    "\n",
    "Quantum mechanics predicts that a spectral feature ought to be Gaussian in shape. However, in real stars, lines are typically broadened due to two effects that essentially cause a Doppler shift in the line: rotation and pressure (temperature). Rotation is clear: one side of the star is moving toward the observer (blue shift) while the other side is moving away (red shift). Because the gas is pressurized, random motions of the individual molecules with be either toward or away from the observer - the net effect is a broadened line. Pressure broadening produces a Cauchy distribution in the feature (for stars, these are typically absorption features):\n",
    "\n",
    "$$\n",
    "P(x) = -\\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x-x_0}{\\gamma} \\right)^2 \\right]}\n",
    "$$\n",
    "\n",
    "By measuring the broadening ($\\gamma$), one can determine the temperature at the photosphere of a white dwarf. The question is, how do we find the broadening of the line?\n",
    "\n",
    "### First, let's load up our libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the data\n",
    "\n",
    "We will load up the spectra of the white dwarf. You can look at the data file if you'd like. It only has two columns: wavelength and flux. We will use `np.genfromtxt` to load the data into a numpy array. This spectra is taken with the UVES instrument on VLT, which has an extremely high resolution ($\\Delta \\lambda =0.1 Å$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.genfromtxt(\"data/HS_2220+2146A_1.dat\", dtype=[('wavelength','f8'),('flux','f8')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's plot the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a two-panel plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "# Plot in the left panel\n",
    "ax[0].plot(spec['wavelength'], spec['flux'])\n",
    "\n",
    "# Plot in the right panel\n",
    "ax[1].plot(spec['wavelength'], spec['flux'])\n",
    "\n",
    "\n",
    "# Set the range of the plot\n",
    "ax[0].set_xlim(3500, 5300)\n",
    "ax[1].set_xlim(4200, 4500)\n",
    "\n",
    "# Add axis labels\n",
    "for a in ax: a.set_xlabel(r'Wavelength ($\\AA$)')\n",
    "ax[0].set_ylabel('Flux')\n",
    "    \n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we looking at? Let's start with the left panel. Here we see the overall spectra shows broad absorption features at specific wavelengths. Comparison with a spectral library will show you that these are hydrogen Balmer lines, at least five of them. In the right panel, we zoom in on one of those lines, Hγ. We would like to fit this line with a Cauchy distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to fit the Hγ line\n",
    "\n",
    "Let's start by trying this by hand. Try to values for the four parameters, `coeff`, `bias`, `center_x`, and `scale` that produce a model that reasonably matches the Hγ absorption feature below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy\n",
    "\n",
    "# Select data within a wavelength range around a particular line\n",
    "idx = np.intersect1d(np.where(spec['wavelength']>4200)[0], \n",
    "                     np.where(spec['wavelength']<4500)[0])\n",
    "data_x = spec['wavelength'][idx]\n",
    "data_y = spec['flux'][idx]\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(data_x, data_y, label='Data')\n",
    "\n",
    "\n",
    "# Set the model parameters\n",
    "coeff = -10  # Magnifies the feature\n",
    "bias = 0.4  # Shifts the spectrum up or down\n",
    "center_x = 4340  # Shifts the spectrum left or right\n",
    "scale = 10  # Sets the strength of the line\n",
    "\n",
    "\n",
    "# Calculate the model fluxes\n",
    "y = coeff*cauchy.pdf(data_x, loc=center_x, scale=scale) + bias\n",
    "\n",
    "# Plot the model output\n",
    "plt.plot(data_x, y, label='Model')\n",
    "\n",
    "\n",
    "# Make the plot pretty\n",
    "plt.xlim(4200, 4500)\n",
    "plt.ylim(0, 0.6)\n",
    "\n",
    "plt.xlabel(r'Wavelength ($\\AA$)')\n",
    "plt.ylabel('Flux')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's use an optimization algorithm\n",
    "\n",
    "We will use `scipy`'s `optimize` library to find the best fit values for those four parameters. First we need to define our chi-square function to minize. Write that in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(p, data_x, data_y):\n",
    "    \"\"\" Function to calculate the chi-squared value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p : tuple\n",
    "        Set of model parameters\n",
    "    data_x : numpy array\n",
    "        Set of wavelengths for the spectrum (angstroms)\n",
    "    data_y : numpy array\n",
    "        Set of fluxes for the spectrum\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi_square : float\n",
    "        Chi-squared value comparing the model to data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import the tuple of model parameters\n",
    "    coeff, bias, center_x, scale = p\n",
    "    \n",
    "    # Calculate the model fluxes\n",
    "    model_y = coeff*cauchy.pdf(data_x, loc=center_x, scale=scale) + bias\n",
    "    \n",
    "    # Calculate chi_square by comparing the model fluxes with the observed fluxes\n",
    "    chi_square = \n",
    "    \n",
    "    return chi_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's minimize!!\n",
    "\n",
    "To run a minimization algorithm, we need to provide the minimizer with a starting position in our four-dimensional parameter space. We can just use the values you found in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Choose the input values previously found\n",
    "coeff = -10  # Magnifies the feature\n",
    "bias = 0.4  # Shifts the spectrum up or down\n",
    "center_x = 4340  # Shifts the spectrum left or right\n",
    "scale = 10  # Sets the strength of the line\n",
    "\n",
    "\n",
    "\n",
    "# Store the input values into a tuple\n",
    "x0 = coeff, bias, center_x, scale\n",
    "\n",
    "# Run the minimizer\n",
    "sol = minimize(chi_square, x0, args=(data_x, data_y))\n",
    "\n",
    "# Calculate the model fluxes from the results of the minimizer\n",
    "coeff_best, bias_best, center_x_best, scale_best = sol.x\n",
    "y_best = coeff_best*cauchy.pdf(data_x, loc=center_x_best, scale=scale_best) + bias_best\n",
    "\n",
    "# Print the central wavelength and scale of the best-fit\n",
    "print(center_x_best, scale_best)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(data_x, data_y, label='Data')\n",
    "\n",
    "# Plot the model\n",
    "plt.plot(data_x, y_best, label='Best-fit Model')\n",
    "\n",
    "plt.xlabel(r'Wavelength ($\\AA$)')\n",
    "plt.ylabel('Flux')\n",
    "\n",
    "plt.xlim(4200, 4500)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import signaltonoise\n",
    "\n",
    "model_diff = y_best - data_y\n",
    "sigma = np.std(model_diff)\n",
    "\n",
    "print(sigma)\n",
    "\n",
    "plt.plot(data_x, model_diff)\n",
    "\n",
    "plt.axhline(0, color='r')\n",
    "\n",
    "# signaltonoise()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "N = 20\n",
    "new_y = np.convolve(spec['flux'], np.ones((N,))/N, mode='valid')\n",
    "\n",
    "plt.plot(spec['wavelength'][N-1:], new_y)\n",
    "\n",
    "# plt.xlim(3750, 4100)\n",
    "\n",
    "plt.axvline(4861.36, color='k', alpha=0.3)\n",
    "plt.axvline(4340.46, color='k', alpha=0.3)\n",
    "plt.axvline(4101.74, color='k', alpha=0.3)\n",
    "plt.axvline(3970.07, color='k', alpha=0.3)\n",
    "plt.axvline(3889.05, color='k', alpha=0.3)\n",
    "plt.axvline(3835.38, color='k', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, try to fit the other Balmer lines. How many can different Balmer lines can you reasonably fit?\n",
    "\n",
    "\n",
    "For reference, the central wavelengths are provided below:\n",
    "\n",
    "Hβ = 4861.36 Å  \n",
    "Hγ = 4340.46 Å  \n",
    "Hδ = 4101.74 Å  \n",
    "Hε = 3970.07 Å  \n",
    "Hζ = 3889.05 Å  \n",
    "Hη = 3835.38 Å   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "1. How many lines were you able to fit?  \n",
    "2. What are the best-fit values of the scale parameters?  \n",
    "3. What are the redshifts in wavelength you find for the separate lines?  \n",
    "4. How do those values change depending on the range of data used for each line?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Non-linear effects in the atmospheres of white dwarfs prevent us from being able to directly translate the scales and depths of these lines into meaningful physical parameters like temperature and surface gravity. Neverthless, this ought to serve as a guide for how one can use the routine `scipy.optimize.minimize` for fitting models to data.\n",
    "\n",
    "We will spend more time fitting models to data in future lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
