{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7641536",
   "metadata": {},
   "source": [
    "# HYPOTHESIS TESTING: EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff169992",
   "metadata": {},
   "source": [
    "# Exercise 1: Z-test with fewer empirical data\n",
    "\n",
    "Repeat Example 1 with a subset of the GC population of the Milky Way, which originally has 81 GCs.\n",
    "\n",
    "The variable `N_SAMPLE` sets the number of GCs to be used. Try small and large values (e.g., 10, 20, 40). Set it to `None` to use all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# the sample\n",
    "\n",
    "N_SAMPLE = # set to a number (10, 20, 40) or `None` for all \n",
    "\n",
    "K_absolute_magnitudes = np.genfromtxt(\"data/GC_MWG_absolute.csv\")\n",
    "if N_SAMPLE is not None:\n",
    "    K_absolute_magnitudes = K_absolute_magnitudes[:N_SAMPLE]\n",
    "sample_size = len(K_absolute_magnitudes)\n",
    "print(f\"SAMPLE SIZE = {sample_size}\")\n",
    "\n",
    "\n",
    "# the model\n",
    "\n",
    "model_mean = 5.5\n",
    "model_std = 1.0\n",
    "\n",
    "\n",
    "# convet to masses\n",
    "\n",
    "mean_mass_to_light_ratio = 0.822                     # Kovlakas et al. 2021\n",
    "M_K_solar = 3.29                                     # Blanton & Roweis (2007)\n",
    "K_band_luminosity = 10.0 ** (\n",
    "    0.4 * (M_K_solar - K_absolute_magnitudes))       # compute the K-band luminosity (in solar units)\n",
    "mass = mean_mass_to_light_ratio * K_band_luminosity  # compute the masses using the M/L ratio\n",
    "log_mass = np.log10(mass)\n",
    "\n",
    "\n",
    "# report on statistics\n",
    "\n",
    "sample_mean = np.mean(log_mass)\n",
    "sample_std = np.std(log_mass)\n",
    "\n",
    "print(f\"MODEL:  Mean = {model_mean:.2f} | Std = {model_std:.2f}\")\n",
    "print(f\"SAMPLE: Mean = {sample_mean:.2f} | Std = {sample_std:.2f}\")\n",
    "\n",
    "sample_sem = st.sem(log_mass)\n",
    "print(f\"Standard error of the mean = {sample_sem:.2f}\")\n",
    "print(f\"Sigma's of difference: {(model_mean-sample_mean) / sample_sem:.2f}\")\n",
    "\n",
    "# set alpha and compute the critical value(s)\n",
    "alpha = 0.05\n",
    "print(\"Significance level: {:7.3f}\".format(alpha))\n",
    "\n",
    "# compute the p-value and report the result\n",
    "sample_mean = np.mean(log_mass)\n",
    "standard_error = model_std / (sample_size ** 0.5)\n",
    "z_score = (sample_mean - model_mean) / standard_error\n",
    "pvalue = 2 * st.norm.cdf(-abs(z_score))\n",
    "\n",
    "print(\"Sample mean       : {:7.3f}\".format(sample_mean))\n",
    "print(\"Standard error    : {:7.3f}\".format(standard_error))\n",
    "print(\"Sample Z score    : {:7.3f}\".format(z_score))\n",
    "print()\n",
    "print(\"p-value           : {:7.3g}\".format(pvalue))\n",
    "\n",
    "if pvalue <  alpha:\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3e7dd",
   "metadata": {},
   "source": [
    "## Question 1.1: What happens with the $p$-value when we decrease the sample size?\n",
    "\n",
    "## Question 1.2: Why is this happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb286a",
   "metadata": {},
   "source": [
    "# Exercise 2: the distance of M31\n",
    "\n",
    "In the file `GC_M31_apparent.dat` we have the **apparent magnitudes** of globular clusters in the Galaxy of Andromeda (M31) [1].\n",
    "\n",
    "Let's load the data and look at the distributions of the absolute magnitudes in the MWG, along with the apparent magnitudes in M31..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Milky Way globular cluster absolute magnitudes\n",
    "absolute_MWG = np.genfromtxt(\"data/GC_MWG_absolute.csv\")\n",
    "apparent_M31 = np.genfromtxt(\"data/GC_M31_apparent.csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(absolute_MWG, bins=\"fd\", histtype=\"step\", label=\"MWG (absolute)\")\n",
    "plt.hist(apparent_M31, bins=\"fd\", histtype=\"step\", label=\"M31 (apparent)\")\n",
    "plt.xlabel(\"Magnitude (mag)\")\n",
    "plt.ylabel(\"Number of GCs\")\n",
    "plt.legend(loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b19ae",
   "metadata": {},
   "source": [
    "We notice that the distributions are **similar** both in shape and in scatter!\n",
    "\n",
    "If we assume that the sample is as **complete** as in the Milky Way, and that there is **no fundamental difference** between GC populations in the two galaxies (e.g., different mass-to-light ratio, GC formation physics), then the mean absolute magnitude **is expected to be the same** in the two galaxies.\n",
    "\n",
    "Assuming that the absolute magnitude of the M31 GCs is the same as that of the Milky Way galaxy (MWG), **we can compute the distance of M31**!\n",
    "\n",
    "The difference between the apparent and absolute magnitude is the *distance modulus* $\\mu$:\n",
    "\n",
    "$$ \\mu = m - M $$\n",
    "\n",
    "which in turn is related to the distance:\n",
    "\n",
    "$$ \\mu = 5\\log_{10}\\frac{D}{\\mathrm{pc}} - 5 $$\n",
    "\n",
    "Therefore:\n",
    "$$ m = M + 5 \\log_{10}\\frac{D}{\\mathrm{pc}} - 5 $$\n",
    "\n",
    "For external galaxies, where Mpc is more convenient:\n",
    "$$ m = M + 5 \\log_{10}\\frac{D}{\\mathrm{Mpc}} + 25 $$\n",
    "\n",
    "By solving for D, we can estimate the distance:\n",
    "$$ D = 10^{\\frac{\\mu}{5} - 5} \\quad [\\mathrm{Mpc}] $$\n",
    "\n",
    "The uncertainties on the mean apparent and mean absolute magnitude (and therefore the distance modulus) are propaged to the uncertainty on the distance. Using **uncertainty propagation** we have:\n",
    "\n",
    "$$ \\sigma_\\mu = \\sqrt{\\sigma_m^2 + \\sigma_M^2} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sigma_D = \\frac{\\ln{10}}{5} \\times D \\times \\sigma_\\mu $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0718fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean values...\n",
    "mean_apparent = np.mean(apparent_M31)\n",
    "mean_absolute = np.mean(absolute_MWG)     # we assume that absolute_M31 == absolute_MGW\n",
    "\n",
    "# ...and the standard errors\n",
    "mean_apparent_err = \n",
    "mean_absolute_err = \n",
    "\n",
    "# report\n",
    "print(f\"Mean apparent (M31): {mean_apparent:6.2f} +/- {mean_apparent_err:4.2f} mag\")\n",
    "print(f\"Mean absolute (MWG): {mean_absolute:6.2f} +/- {mean_absolute_err:4.2f} mag\")\n",
    "\n",
    "# compute the distance modulus and it's uncertainty\n",
    "distance_mod = \n",
    "distance_mod_err = \n",
    "print(f\"Distance modulus   : {distance_mod:6.2f} +/- {distance_mod_err:4.2f} mag\")\n",
    "\n",
    "# now compute the distance in Mpc, as well as it's uncertainty\n",
    "D_M31 = 10.0 ** ((mean_apparent - mean_absolute) / 5.0 - 5)\n",
    "D_M31_err = np.log(10) / 5.0 * D_M31 * distance_mod_err\n",
    "print(f\"Distance of M31    : {D_M31:6.3f} +/- {D_M31_err:.3f} Mpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce47649",
   "metadata": {},
   "source": [
    "This is not a standard distance measurement method!  If we want to validate our procedure, we would need to confirm the derived distance using an independent measurment. \n",
    "\n",
    "There are hundreds of distance estimates of M31. Here we will use the distance from *Ribas et al. 2005* (https://ui.adsabs.harvard.edu/abs/2005ApJ...635L..37R/abstract) who used the eclipsing binary star distance method, to measure the distance of M31: $0.772 \\pm 0.044\\ \\mathrm{Mpc}$.\n",
    "\n",
    "Can we quantify the agreement between the two methods? \n",
    "\n",
    "Or in other words... is the difference in the estimates consistent with $0$ given the uncertainties of the measurements?\n",
    "\n",
    "## Question 2.1: How do you check if the difference is consistent with 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadea38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_R05 = 0.772\n",
    "D_R05_err = 0.044\n",
    "\n",
    "# use `D_M31` and `D_M31_err` from above\n",
    "difference =  \n",
    "difference_uncertainty = \n",
    "print(f\"Difference: {difference:.3f} +/- {difference_uncertainty:.3f} Mpc\")\n",
    "\n",
    "Z_score = \n",
    "p_value = \n",
    "\n",
    "print(f\"Z score: {Z_score:.3f} sigmas\")\n",
    "print(f\"p-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de33b7",
   "metadata": {},
   "source": [
    "# Exercise 3: Are the magnitudes of the MWG and M31 GCs normally-distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49db5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = \n",
    "print(\"p-value (MWG)  = {:.3g}\".format(pvalue))\n",
    "\n",
    "statistic, pvalue = \n",
    "print(\"p-value (M31)  = {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb6106",
   "metadata": {},
   "source": [
    "# Exercise 4: Repeat exercise 3 but using the Anderson-Darling normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMWG:\\n\", st.thefunction(absolute_MWG))\n",
    "print(\"\\nM31:\\n\", st.thefunction(apparent_M31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bbb26",
   "metadata": {},
   "source": [
    "## Question 4.1: how do you interpret the resulting outputs?\n",
    "\n",
    "## Question 4.2: is the result the same as in the Shapiro-Wilk test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645a721",
   "metadata": {},
   "source": [
    "# Exercise 5: do the Milky-Way and M31 GC samples follow the same distribution?\n",
    "\n",
    "First, we compute the absolute magnitudes of the M31 GCs using the distance we found in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74180ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mod_M31 = 24.78                      # this is not from literature, but from Exercise 2\n",
    "absolute_M31 = \n",
    "plt.figure()\n",
    "plt.hist(absolute_MWG, bins=\"fd\", density=True, histtype=\"step\", label=\"MWG\")\n",
    "plt.hist(absolute_M31, bins=\"fd\", density=True, histtype=\"step\", label=\"M31\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d734e8",
   "metadata": {},
   "source": [
    "We can check whether the absolute magnitudes in M31 and MWG are consistent using the **two-sample K-S test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321360b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = st.ks_2samp(, )\n",
    "print(\"statistic = {:.3g}\".format(statistic))\n",
    "print(\"p-value   = {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d51ab",
   "metadata": {},
   "source": [
    "## Question 5.1: can we assume that the distributions are the same?\n",
    "\n",
    "## Question 5.2: Was this a *fair test*? Do you see any way that we may have biased this result?\n",
    "\n",
    "## Question 5.3: Did you expect this result based on our findings in Exercises 3 and 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2573f",
   "metadata": {},
   "source": [
    "# Exercise 6: What would happen if the size of the two samples was doubled?\n",
    "\n",
    "Repeat Exersice 5 with double the sample size! First, answer these questions regarding your expectations:\n",
    "\n",
    "## Question 6.1: are the distributions exactly the same as in with the original sample size?\n",
    "## Question 6.2: would the K-S test result into the same statistic $D$ (distance of CDFs)?\n",
    "## Question 6.3: would the $p$-value be the same?\n",
    "\n",
    "To simulate this, we will take each value twice! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = st.ks_2samp(list()*2, list()*2)\n",
    "print(\"statistic = {:.3g}\".format(statistic))\n",
    "print(\"p-value   = {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c85d2",
   "metadata": {},
   "source": [
    "## Question 6.4: Where you correct in your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a788916",
   "metadata": {},
   "source": [
    "# Exercise 6: Linear correlation and monotonicity in different samples\n",
    "\n",
    "## Question 6.1: What are the correlation and rank coefficients for a \"blob\" of (x, y) data for $x, y \\in \\mathcal{N}(0, 1)$?\n",
    "\n",
    "## Question 6.2: What will happen if we change one data point to be an outlier $x_n = (-10, -10)$?\n",
    "\n",
    "Uncomment the commented line of code to change the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1acacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = st.norm().rvs(100)\n",
    "y = st.norm().rvs(100)\n",
    "\n",
    "# uncomment this to change the last point to an outlier\n",
    "# x[-1], y[-1] = (-10, -10)\n",
    "\n",
    "r, pvalue = st.pearsonr(x, y)\n",
    "print(\"PEARSON  : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.spearmanr(x, y)\n",
    "print(\"SPEARMAN : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.kendalltau(x, y)\n",
    "print(\"KENDALL  : t = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "\n",
    "print()\n",
    "res = st.linregress(x, y)\n",
    "slope, intercept, rvalue, pvalue, slope_stderr = res\n",
    "intercept_stderr = res.intercept_stderr                # for compatibility this value is extract like this\n",
    "print(\"FIT RESULTS (with linregress):\")\n",
    "print(\"    slope          : {:.2f} +/- {:6.2f}\".format(slope, slope_stderr))\n",
    "print(\"    intercept      : {:.2f} +/- {:6.2f}\".format(intercept, intercept_stderr))\n",
    "print(\"    corr. coeff. R : {:+.6f}\".format(rvalue))\n",
    "print(\"    R squared      : {:.6f}\".format(rvalue**2.0))\n",
    "print(\"    p-value        : {:.6g}\".format(pvalue))\n",
    "\n",
    "xx = np.linspace(min(x), max(x), 10)\n",
    "yy = xx * slope + intercept\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"ko\")\n",
    "plt.plot(xx, yy, \"r-\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab903b0b",
   "metadata": {},
   "source": [
    "# Bonus Exercise 1: the standard error of the mean\n",
    "\n",
    "Here, we take the standard normal distribution, i.e. $\\mathcal{N}(0, 1)$. Then, we select the sample size (`n_samples`) and perform `n_experiments` samplings. By taking the sample standard error of the mean, we arrive at a large number of estimate of the population standard error of the mean of `n_samples`.\n",
    "\n",
    "In the figure, we plot the distribution of the estimates, along with their mean, and the expected population standard error of the mean since we know the underlying distributions $\\sigma$.\n",
    "\n",
    "Try different values for the number of samples (`n_samples`). What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = st.norm(0.0, 1.0)\n",
    "n_samples = 10\n",
    "n_experiments = 10000\n",
    "\n",
    "expected_std_err = \n",
    "\n",
    "std_errors = [st.sem(distribution.rvs(size=n_samples)) for i in range(n_experiments)]\n",
    "\n",
    "mean_across_experiments = \n",
    "\n",
    "plt.figure()\n",
    "plt.hist(std_errors, color=\"k\", bins=\"fd\", histtype=\"step\", label=\"Standard errors\")\n",
    "plt.axvline(expected_std_err, color=\"b\", lw=2, label=\"Theoretical value\")\n",
    "plt.axvline(mean_across_experiments, color=\"r\", lw=2, label=\"Mean accross experiments\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e4589",
   "metadata": {},
   "source": [
    "### Question 1: the sample standard error of the mean changes everytime we sample.  Why is that?\n",
    "\n",
    "### Question 2: how does the mean value of the SEMs compare to the theoretical value?\n",
    "\n",
    "### Question 3: Is the sample SEM following a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312d7e",
   "metadata": {},
   "source": [
    "# Bonus Exercise 2: Pitfalls of uncertainty propagation\n",
    "Above we used the classic error propagation formulat to estimate the uncertainty of a function $f = f(x_1, x_2, \\cdots, x_n)$ given the uncertainties of the independent variables:\n",
    "\n",
    "$$ \\sigma_f^2 = \\sigma_{x_1} \\left(\\frac{\\partial f}{\\partial x_1} \\right)^2 \n",
    "              + \\sigma_{x_2} \\left(\\frac{\\partial f}{\\partial x_2} \\right)^2\n",
    "              \\cdots\n",
    "              + \\sigma_{x_n} \\left(\\frac{\\partial f}{\\partial x_n} \\right)^2\n",
    "$$\n",
    "\n",
    "The formula is based on a first-degree approximation using Taylor expanstion. Consequently, it is accurate only for normal distributed data! Also it does not account for correlation between the variables (they are independent), which requires additional terms. \n",
    "\n",
    "More importantly, it is valid only for linear combinations of independent variables! The expression we used above, $10^X$ where $X$ is normally-distributed, cannot follow the normal distribution itself (e.g., it is defined only for positive values, and therefore is not symmetric).\n",
    "\n",
    "When calculating uncertainties, we might significantly underestimate/overestimate if we do not account for correlations, deviations from normality, non-linear combinations etc.\n",
    "\n",
    "An extreme example is:\n",
    "$$ Z = X - Y $$\n",
    "where $X \\in \\mathcal{N}\\left(0, 1\\right)$ and $Y = X$ which means that $Y \\in \\mathcal{N}\\left(0, 1\\right)$. \n",
    "\n",
    "Using error propagation without accounting for the correlation, we have $\\sigma_Z = \\sqrt{\\sigma_X^2+\\sigma_Y^2} = \\sqrt{2}$. \n",
    "\n",
    "Actually it is $\\sigma_Z = \\sqrt{\\sigma_X^2 + \\sigma_Y^2 - 2\\rho \\sigma_X \\sigma_Y} = 0$ where $\\rho=1$ is the correlation coefficient in this case!\n",
    "\n",
    "## sample if not sure...\n",
    "Alternatively, since we know the distribution of the variables, we can find the uncertainty by sampling them (accounting for correlation if necessary) and applying the transformations we want! In our example, the variables are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df349ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_app = st.norm(mean_apparent, mean_apparent_err)\n",
    "dist_abs = st.norm(mean_absolute, mean_absolute_err)\n",
    "\n",
    "N = 1000000\n",
    "samples = 10.0**((dist_app.rvs(N) - dist_abs.rvs(N)) / 5.0 - 5.0)\n",
    "\n",
    "D_mean = \n",
    "D_mean_err = \n",
    "\n",
    "xx = np.linspace(min(samples), max(samples), 100)\n",
    "\n",
    "print(f\"Distance of M31: {D_M31:.3f} +/- {D_M31_err:.3f}\")\n",
    "plt.figure()\n",
    "plt.hist(samples, bins=\"fd\", density=True, color=\"r\", alpha=0.3, label=\"Using sampling\")\n",
    "plt.plot(xx, st.norm(D_mean, D_mean_err).pdf(xx), \"r-\", lw=2, label=\"Using sampling mean +/- std\")\n",
    "plt.plot(xx, st.norm(D_M31, D_M31_err).pdf(xx), \"b--\", lw=2, label=\"Using error propagation\")\n",
    "\n",
    "# plt.plot(xx, st.norm(D_R05, D_R05_err).pdf(xx), color=\"k\", label=\"Ribas+05\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
