{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning (low sample size)\n",
    "\n",
    "**Hyperparameter tuning** == **select** the best hyperparameters of a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;PCA&#x27;, PCA()), (&#x27;RFC&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;PCA&#x27;, PCA()), (&#x27;RFC&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=1000>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 8, 'RFC__n_estimators': 100}\n",
      "\n",
      "Best configuration: mean CV score = 0.862\n",
      "\n",
      "CPU times: user 461 ms, sys: 62.6 ms, total: 524 ms\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(\"\\nBest configuration: mean CV score = %0.3f\\n\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the assessment method is _wrong_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAEWCAYAAAAjJDDoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAB5GElEQVR4nO3deVhTV/oH8O9JwmoA2REhRAVkR5S6L0U7VeteR22ronUdHOXnoKJt1VbbaavWadWp1bZqK6Lt1FY7XZRWUECtCy6A7KhQlUVZEwhbkvP7IwkTWRQEFfX9PE8eknvPPefNvYG8nHPvPYxzDkIIIYQQ0jEIHncAhBBCCCHkfyg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQJ755IwxtoMxtqad6pIwxioYY0Lt6xOMsXntUbe2viOMsVntVV8r2n2PMVbEGCt41G2T+2OMccaY6+OO43FijA1ijGVpf/8m3qfsO4yxffdYn8MYe6HdgySEkBZ6qpMz7R/ZKsaYnDFWxhg7zRj7G2Os/n1zzv/GOX+3hXXd8w825/xPzrmYc65qh9gbfYFwzkdzzr9ua92tjEMCYBkAL865w6Nsmzy5GGNSbdIoaoe6vmKMvXefYusB/Fv7+3e4rW0SQsjj9FQnZ1rjOOdmAFwAfAhgJYBd7d1Ie3wJdVASAMWc89uPo/Enbb8yjWfh96peBzlGLgBSHncQhBDSHp6ZLxHOeTnn/L8ApgGYxRjzAe7+r5wxZsMY+1nby1bCGItnjAkYYxHQJCk/aYdNwvV6BuYyxv4EENNMb0EPxtg5xpiMMfYjY8xK29bzjLGb+jHqeucYY6MAvAlgmra9RO36+mFSbVyrGWO5jLHbjLG9jDEL7TpdHLMYY39qhyTfam7fMMYstNvf0da3Wlv/CwB+B+CojeOrJrZtcp9p1zkzxn7Q1lvMGPt3K2Kv36/a5XMYY2mMsVLGWBRjzEW7nDHGPtbWI2OMJeuObROxvq6tQ84Yu8YYW6i3Lo0xNlbvtUgbd2/t6/7antcyxlgiY+x5vbInGGP/ZIydAqAA0P1ebWm3CWeM5TPG8hhj85je0CRjzIgx9pH22BUyzdC7id62K/S2ndPccdWWdWSM/Vd7bLIZY/P1llfpPo/aZQHaz4rBvfa5dh1njP2dMZYFIKuJpuO0P8u0n50B96qzuePIGFsAYDqAcG09PzXxHq8C6I7//X4aNfe+m9lHM7WfxWLW4PeEMdaXMZagjamQMfave+1vQghpF5zzp/YBIAfAC00s/xNAiPb5VwDe0z7/AMAOAAbaxxAArKm6AEgBcAB7AXQCYKK3TKQtcwLALQA+2jLfA9inXfc8gJvNxQvgHV1ZvfUnAMzTPp8DIBuaLyUxgB8ARDSI7QttXP4AagB4NrOf9gL4EYCZdttMAHObi7PBtk3uMwBCAIkAPta+d2MAg1sRu/5+naAt7wlABGA1gNPa8iMBXADQWduuJ4AuzcQ6BkAPbblh0CRSvbXr1gKIbFA2Tfu8K4BiAC9B8w/NX7SvbfWOy58AvLXxGdynrVEACrTlTQHs075nV+36jwH8F4CV9pj8BOADvW0L8b/P1H79bZt4z3EAtmv3fy8AdwAM166LATBfr+wmADu0z5vd59r1HJrE3QqASRPt6o6jSG/ZAx1H6P2OtvR3/T7v+x387/fQC0AFgKEAjAD8C4AS//s9/APATO1zMYD+j/vvGj3oQY+n//HYA3iob6755OwMgLe0z+v/8ENz3sqPTX3RNfHHX/fl072JZfrJ2Yd6670A1EKTuDyPtiVn0QAW6a3rCaBO+6Wni8NJb/05AK808b6E2pi89JYtBHBC+7xRnA22b3KfARig/UIUNbFNS2LX369HoE0Wta8F0CQ7LgCGQ5NM9gcgaOXn4zCA/9M+dwUgB2CqfR0JYK32+Upok0e9baMAzNI7Lutb0dZuaJMtvba59icDUAmgR4N9eV1vW/3PlDuaSc4AOANQATDTW/YBgK+0z+cBiNE+ZwBuABh6v32ufc2hTXaaeb+646ifnD3QcUQrk7MWvO938L/kbC2Ab/TKdYLm90FXVxyAdQBsWvPZogc96EGPtjyemWHNBroCKGli+SZo/rP/TTsUtaoFdd1oxfpcaHpVbFoU5b05auvTr1sEwF5vmf7VlQpo/vNvyEYbU8O6urYwjub2mTOAXM658gFj199vLgC2aIcUy6A5dgxAV855DIB/A/gUwG3G2OeMMfOmAmWMjWaMndEOdZVB0xNmAwCc82wAaQDGMcZMAYyHpldK1/4UXfvabQcD6NJMvPdsS/v+bzSzrS00vWkX9No6ql3e1Lb6+7EhRwAlnHN5g/K6Y/s9gAGMsS7Q9BypAcTrvecm93lz77kF2uU4tsD93nfDsvXvg3NeCU2vqM5caBLgdMbYef2hb0IIeVieueSMMfYcNH+kTzZcxzmXc86Xcc67Q/PlHMYYG6Fb3UyVzS3XcdZ7LoGmh6gImt4RU724hPjfF3BL6s2D5stOv24lNENerVGkjalhXbdasvE99tkNABLW9MniLYld//3fALCQc95Z72HCOT+tjWEr57wPND2T7gBWNGyQMWYETTLyEQB7znlnAL9CkxzoHADwKjTDb6nahE3XfkSD9jtxzj9sKt4WtJUPwElvW/3PSBGAKgDeem1ZcM7Fets2/Ew1Jw+AFWPMrEH5WwDAOS8F8Bs052G+Bk0Pku593HOfN3zPTWhq3YMex/v9LjR0z/fdwF37U5uYW9e/Cc6zOOevArADsAHAQcZYp1bGQwghrfLMJGeMMXPtf73fQDOkkdxEmbGMMVfGGANQDs3QiFq7uhCac6RaawZjzEv7R389gINcc6uNTADGjLEx2hOwV0NzzotOIQApa/7KvwMA/sEY68YYEwN4H8C3zfRUNUsby38A/JMxZqY9QTsMmvOg7use++wcNF98HzLGOjHGjBljgx4w9h0A3mCMeWvbtGCMTdE+f44x1k+7DysBVON/x0yfITT79w4AJWNsNIAXG5T5RrssBP/rNYN2X4xjjI1kjAm17+V5xpgTmna/tv4D4HXGmKf2c1F/nz3OuRqacwU/ZozZad9jV8bYSL1tZ+t9pt5uJgZwzm8AOA3gA23MftD0BOkf2/0AggH8tcF7bnaft9AdaI6D/u/Mgx7HVv3utfB96xwEMJYxNpgxZgjN72j97xxjbAZjzFZ7XMq0i5v6fBFCSLt5FpKznxhjcmj+a38LmhN+X2+mrBuAY9CcIPwHgO2c8+PadR8AWK0dklneivYjoDlnpgCak5NDAc3VowAWAfgSmv/oKwHoX735nfZnMWPsYhP17tbWHQfgOjRfZktaEZe+Jdr2r0HTo7hfW39LNLnPtEnfOGjOo/oTmvc27UFi55wfgqbX4hvGmAzAFQCjtavNoUlmSqEZuiqGZqi1YR1yaPb9f7RlX4PmpHv9Mvna9zAQwLd6y29A05v2JjRJxw1oenWa/P25X1uc8yMAtgI4Ds2Q8Bntqhrtz5W65dr3ewya8/J0234Czcn82dqf9/IqNOd/5QE4BOBtzvkxvfX/heYYFnDOE/VivNc+vy/OuQLAPwGc0v7O9G/DcdwFwEtbz+EWhnC/962LMwXA36H5zOdr29f/PRwFIIUxVgFgCzTnbVa1MAZCCHkguisRCSGPCWPME5pExai1PZ+EEEKePs9CzxkhHQ5jbBLT3I/LEprepJ8oMSOEEAJQckbI47IQwG0AV6E5Ty/k8YZDCCGko6BhTUIIIYSQDoR6zgghhBBCOpBHOmGxjY0Nl0qlj7JJ8qwqK268rLN142Xksbpw4UKjZX369HkMkXRsFy5cKOKc296/JCHkafBIhzUDAwN5QkLCI2uPPMPmjWq87Mujjz4Ock+a2+PdjU61aIwxdoFzHvi44yCEPBo0rEkIIYQQ0oFQckYIIYQQ0oFQckYIIYQQ0oE80gsCCCGEdAwXLlywE4lEXwLwAf2jTsijpAZwRalUzuvTp8/tpgpQckaeTuOmP+4ICOnQRCLRlw4ODp62tralAoGArsIg5BFRq9Xszp07XgUFBV8CGN9UGUrOyNNpwszHHQEhHZ0PJWaEPHoCgYDb2tqWFxQU+DRb5n6VMMZ2M8ZuM8au6C3bxBhLZ4wlMcYOMcY6t1PMhBBCHg0BJWaEPB7a371mc7CWnGfwFYCGN436HYAP59wPQCaANx40QEIIIYQQ8j/3Tc4453EAShos+41zrtS+PAPA6SHERggh5CnGGOszYcKEbrrXdXV1sLS09A8KCnJ9nHGR1gkLC3Ncu3atfVvLkP9pj3PO5gD4trmVjLEFABYAgEQiaYfmyLNg5Lu/PPQ2otaMeehtEEKaZ2Jios7IyDCpqKhgYrGYHzp0yNze3r7uccfVWkqlEiLRwzuFu66uDgYGBg+tftLxtOnTxBh7C4ASQGRzZTjnnwP4HNBM39SW9gghhDwk3+50xO+HurRLXV8ebTxpajNeeOGF8u+++67z66+/XnrgwAGryZMnl5w+fVoMADKZTDB37lxJenq6iVKpZG+99VbejBkzyjIyMgxfe+21blVVVQIA2LJly59/+ctfKn/++Wez9evXO1pZWdVlZGSY+Pr6Kg4fPnxdILh7kOi9996z27Nnj61QKOTu7u7VP//887Xy8nLB3LlzJUlJSaYA8Oabb+bNnj27bOfOnVabN2924JyzF154oeyzzz67BQCmpqYB06dPvxMXF2e+devWP69evWr42Wef2dfV1bHevXtX7t27N7dhwrZ8+fIuR48e7VxTUyMIDAysiIyMzBUIBLhy5YrRggULXIqLi0VCoZB/9913165fv2749ttvO1pYWKiuXbtmnJqamhIcHOySlJRkKhQKsXHjxhvjxo2TJyQkGL/++uvd6urqmFqtxvfff3/VxcWlbvz48d3z8/MN1Wo1Cw8Pz5s/f36pfix9+/bt6evrqzh79qxYoVAI9uzZc/2f//xnl4yMDJMJEyaUbN26NQ8A3nnnHfvIyEgbAJg5c+adtWvX3gaAlStXOnz77bc21tbWdY6OjrUBAQEKAEhJSTH629/+JikpKREZGxurv/zyy9yAgIDq++3/ln5enhUPnJwxxmYDGAtgBKfJ8AghhDyAmTNnlrz99ttdpk2bVpaWlmY6d+7cYl1y9uabb3YJCgqSfffddzlFRUXCwMBAz/Hjx8scHR2V8fHxmaampjw5Odno1Vdf7X7lypU0AEhLSzO5fPnyNalUWtenTx+P33//XTxy5MgK/Ta3bt3qkJubm2xiYsKLioqEALBq1aou5ubmqszMzFQAuHPnjjAnJ8fgnXfe6XrhwoU0W1tb5ZAhQ9wjIiI6z5w5s6yqqkrQr1+/yi+++OLmxYsXjTds2OCQkJCQbmRkxGfMmCHZsWOH9eLFi4v1212xYsXtjz76KB8AJk6c2O2bb76xeO2118pfe+21bsuXLy8IDg4uUygUTKVSsevXrxumpqaaXrp0KcXDw6P27bfftmeMITMzM/XSpUvGL730ktvVq1evbNu2zXbRokWFISEhJdXV1UypVOLgwYMWDg4OdSdOnMgGgOLiYmFT+97Q0FB95cqVtHfffdduypQprufPn0+zs7NTSqVS3zfffLMwKyvLaP/+/dYXLlxI45yjT58+niNGjJCr1Wp26NAhq+Tk5NS6ujr06tXLS5eczZs3z+Xzzz/P9fX1rYmJiekUEhIiOXPmTOb99j+52wMlZ4yxUQDCAQzjnCvaNyRC2m5G2dlGy/Z17vcYIiGE3Eu/fv2qbt68afTFF19YvfDCC+X6606cOGEeFRXVeevWrQ4AUFNTw7Kzsw1dXFzq5s6d65KammoiEAiQm5trpNvG19e3skePHnUA4O3trbh69aphwzZ79uxZNWnSpG7jx48vmz59ehkAxMXFmX/zzTf1PTi2traqqKgos/79+8sdHR2VADBt2rSS2NhY8cyZM8uEQiFmz55dCgBHjx41u3Lliqm/v78nAFRXVwvs7OyUDds9cuSI2b/+9S+H6upqQVlZmcjLy6uqtLRUXlhYaBgcHFwGAKamphwABwA/P79KDw+PWgA4ffq0eMmSJbcBICAgoNrR0bE2OTnZeMCAAZUfffRRl5s3bxq+8sorpb6+vjW9e/eueuutt5xDQkK6TpgwoXzUqFEVDWMBgEmTJpUBgL+/f5Wrq2uVi4tLHQA4OzvXXLt2zfDEiRPil156qczc3FwNAGPGjCk9fvy4mVqtxksvvVRmZmamBoAXX3yxDADKy8sFly5dEk+ZMqWHro3a2lrWkv1P7nbf5IwxdgDA8wBsGGM3AbwNzdWZRgB+Z4wBwBnO+d8eYpyEtMrM8nONllFyRkjHNGrUqLK3337b+bfffsu4fft2/fcS5xwHDx7M9vf3r9EvHxYW5mhnZ1f3/fffX1er1TAxMemjW2dkZFQ/kiMUCqFUKhslB8ePH886cuSI2Y8//mjx0UcfdcnIyEhpbcyGhoZq3bAl55xNmTKl+NNPP73VXHmFQsGWLVvmcvbs2VRXV9e6sLAwx+rq6ntelGdqaqq+Xxx/+9vfSoYMGVJ56NAhi7Fjx7pt27Ytd/z48fKLFy+mfv/99xZr1qzpeuzYMZmux06fsbExBwCBQHDXfhMIBE3ut/tRqVQwMzNTpqenp96rXFP7n86pu1tLrtZ8lXPehXNuwDl34pzv4py7cs6dOee9tA9KzAghhDyQkJCQouXLl+f17du3Sn95UFCQbPPmzfZqtSZHOXXqlAkAlJeXC7t06VInFAqxfft2a5VK1eK2VCoVrl69ajhu3Dj5p59+equiokJYXl4uHDZsmOzjjz+205W7c+eOcMiQIZVnz541y8/PFymVSnz33XdWzz//fKNeqFGjRsl+/vlny1u3bokAoLCwUJiZmXlXj51CoRAAgIODg7K8vFzw008/WQKApaWl2sHBoTYiIqIzAFRVVTG5XN7ou3nQoEEV+/btswKApKQko/z8fEM/P7/q1NRUQ09Pz5rVq1ffHjlyZNnly5dNcnJyDMzMzNSLFi0qCQsLK7h8+bJpi3eQnqCgoIpff/21s1wuF8hkMsGvv/5qGRQUJB8+fHjFr7/+2rmiooKVlpYKfv/9984AYGVlpXZycqrdvXu3JQCo1Wr88ccfJi3Z/w8S39OMZggghBACTFuYh2kL8x5H0z169KhbvXp1ozkGP/zww7wFCxZIPDw8vNRqNXN2dq45fvx49tKlS29Pnjy5xzfffGM9fPjwchMTk/v2MOkolUr22muvdZPL5ULOOZs3b95tGxsb1QcffJD/+uuvS9zc3LwFAgF/880382bNmlX29ttv3xo2bJi77oKAGTNmlDWss0+fPtWrV6++NWLECHe1Wg0DAwO+devWP93d3Wt1ZWxsbFTTp0+/4+np6W1ra6v09/ev1K3bt2/f9fnz57u8++67jgYGBvy777672rCN8PDw28HBwS7u7u5eQqEQO3fuzDExMeH79u2z+s9//mMtEom4ra1t3bvvvpt/8uTJTm+88YaTQCCASCTi27dvz23p/tE3ePBgxWuvvVbcu3dvT0BzQcCgQYOqAGDSpEklPj4+3tbW1nV+fn717+XAgQPX5s+f77Jhw4YuSqWSTZo0qWTAgAH1SXdz+/9B4nuasUd5Ln9gYCBPSEh4ZO2RJ1dbb6URlbutcZ0uS+4uQ7fSeOy0p0Xcha4vaowxdoFzHtiedSYmJub4+/sXtWedhJCWS0xMtPH395c2ta4lMwQQQgghhJBHhJIzQgghhJAOhJIzQgghhJAOhJIzQgghhJAOhJIzQgghhJAOhJIzQgghhJAOhJIzQgghhJAOhJIzQgghj8XKlSsdXF1dvd3d3b08PDy8YmJiOj3umBYuXOjk6urqvXDhQif95WFhYY5r1661b2v969evt2tqBoD2NnnyZOmePXss21rmQTS3D/U1tz8zMjIM3dzcvJvaZtu2bdYuLi4+Li4uPtu2bbNuru5Ro0Z1T01NNQSA+Ph4U3d3dy+JROIze/ZsZ91sE/qKi4uFw4cPd+3Zs6eXq6ur95YtW6wBIDMz09DLy8vTw8PDy9XV1Xvjxo22gGYWhyFDhri5ubl5f/jhh7a6el599VWXkydP1s/G8P7779t+8sknzcZ5LzRDACGEkEfu2LFjnaKiojonJyenmpiY8Pz8fFFNTU2r53PUV1dXh7bO0bh//36b0tLSy7p5M9vbzp077efPn1+imzT8afQw9mFhYaFww4YNjhcuXEgVCAQICAjweuWVV8psbW3vml0gISHBWKVSMS8vr1oAWLRokctnn32WGxQUVPn888+7HTx40Hzq1Kky/W02bdpk27Nnz6qYmJjsvLw8kaenp8/ChQtLJBJJ3YULF9JNTEx4eXm5wMvLy3vq1Kllp06dMh0wYEDFBx98kN+nTx+PVatW3fnjjz9MVCoVBg8erNDVu2TJkuK+fft6LF26tLi175eSMz1tvSt9S9Bd6QkhHY3D8ct97l/qwRQE9brQ1PJbt24ZWFlZKU1MTDgAdOnSRalbFxsba7p06VKJQqEQGBoa8ri4uAwjIyMeHBzskpSUZCoUCrFx48Yb48aNk2/dutX68OHDlgqFQqBSqVh0dHTW3LlzJenp6SZKpZK99dZbeQ2nXFKr1QgJCXGKiYmxYIzxFStW5M+fP790+PDhrgqFQujj4+O1bNmy/Pnz55fqb5eUlGTaq1cvj9LSUlFoaGjBsmXLigBgzZo19ocOHbKqra1lY8aMKfv444/zZDKZYPz48d3z8/MN1Wo1Cw8PzyssLDS4ffu2wbBhw9wtLS2VZ8+ezdSvv2vXrr4TJ04siY6OthCJRHzHjh25q1at6pqbm2u0ZMmSwvDw8DvNxa5WqzF79mxJXFycuaOjY62BgUF98hcfH28aFhbmrFAoBJaWlsrIyMgcFxeXuuaO2enTp01CQkJcqqqqBC4uLjX79+/PsbW1VfXt27dnnz59Kk6ePGkul8uFO3bsyBk1atRdc4023IdDhw6tnDVrlrSkpERkbW2t3Lt3b46bm1ut/jbx8fGm8+bNkwLA888/f1fipHP48GGLoUOHyuzt7VUAMHToUNkPP/xgsXDhwhL9cl999ZX1uHHjygAgNzfXoKKiQjBixIhKAJg+fXrx4cOHLRsmZ4wxyOVyoVqthkwmE1hYWCgNDAy4UPi/KT+rqqqYrtfNwMCAKxQKQW1tbf0sS2+99VbX3bt33zVNlpmZmdrJyanm+PHjpkFBQQq0Ag1rEkIIeeQmTpwoy8vLM5RKpT4zZsyQ/PLLL2IAqK6uZtOnT+/xySef/JmRkZEaGxubIRaL1Rs2bLBjjCEzMzN1//791xYsWCBVKBQMAFJSUkx//PHHq+fPn8948803uwQFBcmSk5PT4uPjM1avXu0kk8nu+q7bu3dv5+TkZJO0tLSU6OjozLVr1zrl5uYaxMTEZBsZGanT09NTGyZmAJCWlmZy8uTJjDNnzqRv2rTJMScnx+CHH34wz87ONk5KSkpLS0tLvXz5sumRI0fEP/zwg7mDg0NdRkZGalZWVsrLL78sW7169W07O7u62NjYzIaJmY5EIqlNT09P7devX8WcOXOkP/3009WzZ8+mb9iwwfFesUdERHTOzs42ys7OvrJ///7rFy9eFANATU0NCw0Nlfz4449XU1JS0mbNmlW0fPnyrvc6NrNnz+72/vvv38zMzEz19vauWrlypaNunVKpZMnJyWkbNmy4sX79eseG2zbchyEhIZLp06cXZ2Zmpk6bNq04JCTEueE2c+fOleqOd3Mx3bp1y8DJyak+qevatWvtrVu3GnWTnj17Vty/f38FoEnOunTpUp+Euri41Obn5zfaJjw8/HZWVpaxvb29X+/evb03btx4Q5eYZWdnG7i7u3t169bNLzQ0tEAqldZNmjRJlpuba9i7d2/PkJCQ25GRkRa9evVSSKXSRglv7969K0+cOGHW3PtqDiVnhBBCHjkLCwv1lStXUv/973/n2traKmfNmtVj69at1klJScZ2dnZ1w4YNUwCAlZWV2sDAAKdPnxbPnDmzGAACAgKqHR0da5OTk40BYMiQIfU9KidOnDD/+OOPu3h4eHgNHjy4Z01NDcvOzjbUbzs+Pt5s6tSpJSKRCM7Ozsp+/fpV6J8r1JzRo0eXicVi3qVLF+WAAQNk8fHxnY4ePWoeFxdn7uXl5eXt7e119epV4/T0dOPevXtXxcfHm4eEhHQ9evSo2NraukWTe0+dOrUMAHx9fRW9e/eutLS0VDs6OioNDQ3VRUVFwuZij42NrV8ulUrrBgwYIAeApKQko6ysLJPhw4e7e3h4eG3atKlLXl5es2O/xcXFQrlcLhwzZkwFAMyfP7/4zJkzYt36KVOmlALAwIEDK2/evGnYXD06ly5d6rRgwYISAAgJCSm5cOGCWH99UVGRUC6XC0ePHl0BAHPmzGn1EKC+O3fuGDg4ODTbK9iUw4cPW/j4+FQVFhYmnTt3LnXZsmWSkpISAQC4urrWZWZmpqalpV3Zv3+/zY0bN0QGBgb46aefrqelpaW+/vrrpdu2bbNfs2ZNwbx585xGjRrVPTIy0kJXt52dnfJe+7s5NKxJCCHPuOaGHh82kUiEsWPHyseOHSv38/OrioiIsNb1erSGqalp/RAe5xwHDx7M9vf3r2nfaDXDXw1fc86xdOnS/BUrVjSaRP7ixYup33//vcWaNWu6Hjt2TPbRRx/l368NY2NjDgACgQCGhoZct1wgEKCurq7V5+Rxzpmrq2vV5cuX01u77b3iE4lEUKlUbTpHsDW6du1aFxsbW98DdevWLcNhw4bJG5YzMjJSV1VVCQDAxcWlTr+nLDc311C/J03n66+/tl61alWBQCCAj49PjbOzc01iYqKx/lCkVCqt8/DwqDp27JjZ66+/Xt+runHjRtvXXnut+MSJE2ILCwvVjh07rg0YMKDn9OnTywGgurpaYGJi0urzC6nnjBBCyCOXmJholJycbKR7fenSJRMnJ6daPz+/6tu3bxvExsaaAkBpaamgrq4OgwYNqti3b58VoOkNys/PN/Tz86tuWG9QUJBs8+bN9rrzg06dOmXSsMzQoUPlBw8etFIqlcjLyxOdO3dOPGTIkMr7xXzkyJHOCoWCFRQUCM+cOWM2ePDgytGjR8siIiJsysvLBQBw/fp1g1u3bolycnIMzMzM1IsWLSoJCwsruHz5sikAdOrUSaUr+yCai33YsGH1y3Nzcw3OnDljBgB+fn7VJSUlomPHjnUCNMOcCQkJxs3Vb21trTI3N1cdPXpUDAC7du2yHjBgQEVz5e8nICCg8ssvv7QEgJ07d1oFBgbeVZeNjY3KzMxMFRUVJQaAr776yqqpeiZOnFgeGxtrfufOHeGdO3eEsbGx5hMnTixvWM7Nza06LS3NCNAkZ2KxWB0dHd1JrVYjMjLSesKECWUNt+natWvtb7/9Zg4AN27cEF27ds3Yw8Oj9urVqwYVFRUMAO7cuSM8f/682Nvbu/4zd+fOHeGRI0cs/v73vxdXVlYKBAIBGGOorq6uP76ZmZlGPj4+Va3db9RzRp5KI12WPO4QCCH3IJPJhKGhoRKZTCYUCoVcKpXWfP3117nGxsY8MjLyamhoqKS6ulpgbGysjouLywwPD78dHBzs4u7u7iUUCrFz584c3cUE+j788MO8BQsWSDw8PLzUajVzdnauOX78eLZ+mZkzZ5adPn1a7Onp6c0Y4+vWrbspkUiUDetqyNPTUzFw4MCepaWlouXLl+dLpdI6qVRal5KSYvzcc895AJpevMjIyOvp6elGb7zxhpNAIIBIJOLbt2/PBYBZs2YVjRo1yt3e3r62ufPO7qW52GfOnFkWHR1t7urq6uPo6FgTEBBQAWh6ur755puroaGhErlcLlSpVCwkJKQwMDCwUWKrs2fPnushISEuoaGhAolEUnPgwIGc1saps2PHjj+Dg4OlW7ZscdBdENCwzK5du3LmzZsnZYw1e0GAvb29asWKFXl9+vTxBIDw8PA83VC2vtGjR5fFxMSYTZw4UQ4An376ae7cuXO7VVdXs6CgINmUKVPKAU2Pl7aeO//85z/zp0+fLnV3d/finLN33nnnZpcuXZSHDh0yX7lypZOuh3Tx4sUFffv2rU+0Vq1a5fjmm28WCIVCvPzyy+WfffaZbc+ePb1ff/31O7oy58+fF2/YsCGvtfut/kqDRyEwMJAnJCQ8svZai67W7DjoWDwbGg4TAZphKXI3xtgFznlge9aZmJiY4+/v32gojpAnWUVFBRs0aFDPCxcupD+s26G01KlTp0w2bdrkcPjw4etNrU9MTLTx9/eXNrWOhjUJIYQQ8lQQi8V87dq1edevX7/vxQoP2+3btw02bNhw60G2pWFNQgghhDw1Jk+e3OTQ6KM2adKkB46Des4IIYQQQjoQSs4IIYQQQjoQSs4IIYQQQjoQSs4IIYQQQjoQSs7IUykqd1ujByGkY1m5cqWDq6urt7u7u5eHh4dXTExMp8cd08KFC51cXV29Fy5c6KS/PCwszHHt2rX2ba1//fr1dnK5/KF/906ePFm6Z88ey7aWeRDN7UN9ze3PjIwMQzc3N++mthkyZIibmZlZr6CgINd7tT9nzhznI0eOiAEgPT3d0M/Pz0MikfiMGTOme3V1daP799TU1LCXX35Z6u7u7tW9e3fvN954w0G3bt26dXaurq7ebm5u3uPGjeumm891/Pjx3dzd3b0WL15cP09peHh4l4iIiM661wcOHLBYunRpo/lHW+K+HxDG2G7G2G3G2BW9ZVaMsd8ZY1nan+1+cAkhhDy9jh071ikqKqpzcnJyamZmZurx48czu3fvXnv/LZtXV9eqKRWbtH//fpv09PSUnTt33mxzZU3YuXOnfUVFxVPdMfKw9uHy5csLdu7c2eQ9w3QKCgqEFy5c6KSbqzMsLMxp8eLFhX/++ecVCwsL5ZYtW2wabrNnzx7L2tpaQWZmZmpiYmLa3r17bTMyMgyvX79u8Pnnn9tfvnw5NSsrK0WlUrEvv/zS6uzZsyYmJibqzMzM1IsXL5oWFxcLc3NzDRISEjrNnDmzTFfvtGnTyqOiojo/SDLekltpfAXg3wD26i1bBSCac/4hY2yV9vXK1jZOCCHk8YuO6dHnYdU9YvjVJuftvHXrloGVlZVSd5f/Ll261N+hPzY21nTp0qUShUIhMDQ05HFxcRlGRkY8ODjYJSkpyVQoFGLjxo03xo0bJ9+6dav14cOHLRUKhUClUrHo6OisuXPnStLT002USiV766238mbMmFGm37ZarUZISIhTTEyMBWOMr1ixIn/+/Pmlw4cPd1UoFEIfHx+vZcuW5c+fP79Uf7ukpCTTXr16eZSWlopCQ0MLli1bVgQAa9assT906JBVbW0tGzNmTNnHH3+cJ5PJBOPHj++en59vqFarWXh4eF5hYaHB7du3DYYNG+ZuaWmpbDhDQNeuXX0nTpxYEh0dbSESifiOHTtyV61a1TU3N9doyZIlheHh4Xeai12tVmP27NmSuLg4c0dHx1oDA4P6+Rzj4+NNw8LCnBUKhcDS0lIZGRmZ4+Li0mwme/r0aZOQkBCXqqoqgYuLS83+/ftzbG1tVX379u3Zp0+fipMnT5rL5XLhjh07ckaNGnXXdEwN9+HQoUMrZ82aJS0pKRHpZghwc3O7KwmPj483nTdvnhRAszMEAMCECRPkP//8s1lz6wFg3759liNGjJDpjvMff/xh9uOPP14DNJOqv/POO44rV668o78NYwwKhUJQV1eHyspKZmBgwDt37qzSfaYqKysFRkZGqqqqKoGTk1OdgYEBr6qqEqhUKiiVSoFIJOIrV650XL9+/V0zAQgEAgwcOFD+7bffWsybN++uz9L93Deb45zHAShpsHgCgK+1z78GMLE1jRJCCHm2TZw4UZaXl2colUp9ZsyYIfnll1/EAFBdXc2mT5/e45NPPvkzIyMjNTY2NkMsFqs3bNhgxxhDZmZm6v79+68tWLBAqhtiSklJMf3xxx+vnj9/PuPNN9/sEhQUJEtOTk6Lj4/PWL16tZNMJrvru27v3r2dk5OTTdLS0lKio6Mz165d65Sbm2sQExOTbWRkpE5PT09tmJgBQFpamsnJkyczzpw5k75p0ybHnJwcgx9++ME8OzvbOCkpKS0tLS318uXLpkeOHBH/8MMP5g4ODnUZGRmpWVlZKS+//LJs9erVt+3s7OpiY2Mzm5u6SSKR1Kanp6f269evYs6cOdKffvrp6tmzZ9M3bNjgeK/YIyIiOmdnZxtlZ2df2b9///WLFy+KAc2QXWhoqOTHH3+8mpKSkjZr1qyi5cuXd22qbZ3Zs2d3e//9929mZmament7V61cubJ+aE6pVLLk5OS0DRs23Fi/fn2jIbuG+zAkJEQyffr04szMzNRp06YVh4SEODfcZu7cuVLd8b5XXC1x+vRpcWBgYCUAFBYWiszMzFQGBpq5z6VSaW1hYWGjm9POnj271NTUVG1nZ+ffrVs3v8WLFxfY29urunXrVvf3v/+9oFu3bn52dnb+ZmZmqpdfflnWu3fvahsbG6W3t7fX6NGjy1JSUozUajUGDx6saFh3YGBgZXx8vLi17+NBb0JrzznP1z4vANDsODxjbAGABQAgkUgesDlCSFNomivypLKwsFBfuXIl9ejRo2bR0dFms2bN6rF27dqb/fv3V9jZ2dUNGzZMAQBWVlZqQPOlu2TJktsAEBAQUO3o6FibnJxsDABDhgyR6eZZPHHihHlUVFTnrVu3OgCa5CQ7O9uwd+/e9XNJxsfHm02dOrVEJBLB2dlZ2a9fv4qTJ0+auri4NJpIW9/o0aPLxGIxF4vFygEDBsji4+M7xcfHi+Pi4sy9vLy8AEChUAjS09ONR4wYIX/rrbecQ0JCuk6YMKG8YQ9Tc6ZOnVoGAL6+vorKykqBpaWl2tLSUm1oaKguKioSNhd7bGxs/XKpVFo3YMAAOaCZJD4rK8tk+PDh7oCmN8nW1rbZXrPi4mKhXC4XjhkzpgIA5s+fXzxlypTuuvVTpkwpBYCBAwdWrlix4r534b906VKnI0eOXAWAkJCQknXr1t11HlpRUZFQLpcLdcOQc+bMKY6JibFoyb5qSmFhoYG9vf1950nVFxsbayoQCHhBQUFSUVGRcNCgQR4vvfSSzNbWVvXLL790zs7OTra2tlaNGTOm+/bt260WLVpUsnv37hu67YcPH+66e/fu3JUrVzokJyebjhgxQqbrVXVwcFAWFBS0eraCNs8QwDnnjLFmJ8PjnH8O4HNAM7dmW9sjhBDSvpobenzYRCIRxo4dKx87dqzcz8+vKiIiwrp///6Neh/ux9TUtH4Ij3OOgwcPZvv7+9e0b7SN54LVTYi9dOnS/BUrVjSap/TixYup33//vcWaNWu6Hjt2TPbRRx/lNyzTkLGxMQc0Q2KGhob135kCgQB1dXWNJ6O9D845c3V1rbp8+XJ6a7e9V3wikQgqlarV8TxsxsbG6qqqKgEA2NvbK+VyubCurg4GBgbIyckxtLe3b3ReY0REhPXIkSPLjYyMeNeuXZXPPfdcxenTpzsJBAJIJJIaR0dHJQBMnDix7PTp0+JFixbVjybu27evc69evRQymUxw7do1419//fXa4MGD3RYsWFBiZmamrqqqYsbGxuqGbd7Pg56UWMgY6wIA2p+3H7AeQgghz6DExESj5ORkI93rS5cumTg5OdX6+flV37592yA2NtYUAEpLSwV1dXUYNGhQxb59+6wATW9Qfn6+oZ+fX3XDeoOCgmSbN2+2V6s134enTp0yaVhm6NCh8oMHD1oplUrk5eWJzp07Jx4yZEjl/WI+cuRIZ4VCwQoKCoRnzpwxGzx4cOXo0aNlERERNuXl5QIAuH79usGtW7dEOTk5BmZmZupFixaVhIWFFVy+fNkUADp16qTSlX0QzcU+bNiw+uW5ubkGZ86cMQMAPz+/6pKSEtGxY8c6AZqexISEBOPm6re2tlaZm5urjh49KgaAXbt2WQ8YMKBFvX5NCQgIqPzyyy8tAWDnzp1WgYGBd9VlY2OjMjMzU0VFRYkB4KuvvrJ60LYAoGfPntWZmZlGgCah7d+/v1x3Reru3butx44dW9ZwG4lEUnv8+HFzAJDJZIKLFy928vX1rZZKpbUXL14Uy+VygVqtRkxMjJmnp2f9Z66mpoZt27bNbt26dQWVlZUCXUeVWq1mNTU1DAAyMjKMvb29q1r7Ph605+y/AGYB+FD788cHrIcQQsgzSCaTCUNDQyUymUwoFAq5VCqt+frrr3ONjY15ZGTk1dDQUEl1dbXA2NhYHRcXlxkeHn47ODjYxd3d3UsoFGLnzp05uosJ9H344Yd5CxYskHh4eHip1Wrm7Oxcc/z48Wz9MjNnziw7ffq02NPT05sxxtetW3dTIpHcdyjM09NTMXDgwJ6lpaWi5cuX50ul0jqpVFqXkpJi/Nxzz3kAml68yMjI6+np6UZvvPGGk0AggEgk4tu3b88FgFmzZhWNGjXK3d7evra5887upbnYZ86cWRYdHW3u6urq4+joWBMQEFABaHq6vvnmm6uhoaESuVwuVKlULCQkpDAwMLBRYquzZ8+e6yEhIS6hoaECiURSc+DAgZzWxqmzY8eOP4ODg6Vbtmxx0F0Q0LDMrl27cubNmydljN3zgoA+ffr0vHbtmnFVVZXQ3t7eb/v27TkN59EcP358+WeffWYbFhZWBACbN2++OW3atB7vvfdeV29vb8X//d//FQFAZGSkxfnz5zt98skneeHh4bdfeeUVqaurqzfnHK+99lpRv379qgBg3LhxpX5+fp4ikQje3t6KsLCw+osJNmzYYDt9+vRiMzMzdb9+/aqqqqoE7u7uXiNGjCi3sbFRAUBcXJzZg0x+zji/90gjY+wAgOcB2AAoBPA2gMMA/gNAAiAXwFTOecOLBhoJDAzkCQkJrY3xkaHzdzqOth6Lpu5rNtJlyd1lnoJj8aR/ZhsOEwGaYSlyN8bYBc55YHvWmZiYmOPv799oKI6QJ12fPn16RkVFZesSpMflxo0boqlTp3b/448/mkzCExMTbfz9/aVNrbtvzxnn/NVmVo1oeYiEEEIIIQ/fpk2bbl69etXQxsam1cOJ7enatWuGmzdvvnH/ko21+YIAQgghhJCOYvjw4fc9f/BR0F1x/CCe6rsUE0IIIYQ8aSg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQ8lisXLnSwdXV1dvd3d3Lw8PDKyYmptPjjmnhwoVOrq6u3gsXLrxrmqGwsDDHtWvXNjtVYUutX7/eTi6XP/Tv3smTJ0t1N19tS5kH0dw+1Nfc/szIyDB0c3Pzbrj89OnTJr169fLQfV6++OKLZuOeM2eO85EjR8QAkJ6ebujn5+chkUh8xowZ0726urrR/XtqamrYyy+/LHV3d/fq3r279xtvvOGgWzdlyhSplZWVf8OYQkJCurq7u3tNmjRJqlu2fft2q/Xr19vpXp87d85k8uTJUjwASs4IIYQ8cseOHesUFRXVOTk5OTUzMzP1+PHjmd27d280tU5r1NU1O2Vki+3fv98mPT09ZefOnTfbXFkTdu7caV9RUfFUf/c+jH0oFovVERER17Ozs1N+++23rDfffNO5qKhI2LBcQUGB8MKFC510c3WGhYU5LV68uPDPP/+8YmFhodyyZYtNw2327NljWVtbK8jMzExNTExM27t3r21GRoYhAMyZM6fov//9b5Z++eLiYmFiYqJpZmZmqqGhIT937pxJRUUFi4iIsFm5cmX9TWr79u1blZ+fb5iVlfXo59YkhBDyZHvnnXf6PMS6m5y389atWwZWVlZK3V3+u3TpUn+H/tjYWNOlS5dKFAqFwNDQkMfFxWUYGRnx4OBgl6SkJFOhUIiNGzfeGDdunHzr1q3Whw8ftlQoFAKVSsWio6Oz5s6dK0lPTzdRKpXsrbfeypsxY0aZfttqtRohISFOMTExFowxvmLFivz58+eXDh8+3FWhUAh9fHy8li1blj9//vxS/e2SkpJMe/Xq5VFaWioKDQ0t0E1uvWbNGvtDhw5Z1dbWsjFjxpR9/PHHeTKZTDB+/Pju+fn5hmq1moWHh+cVFhYa3L5922DYsGHulpaWyoYzBHTt2tV34sSJJdHR0RYikYjv2LEjd9WqVV1zc3ONlixZUhgeHn6nudjVajVmz54tiYuLM3d0dKw1MDCon88xPj7eNCwszFmhUAgsLS2VkZGROS4uLs1msqdPnzYJCQlxqaqqEri4uNTs378/x9bWVtW3b9+effr0qTh58qS5XC4X7tixI6fhhO4N9+HQoUMrZ82aJS0pKRHpZghwc3O7KwmPj483nTdvnhRAszME+Pn51c+VKpVK66ysrJT5+fmihjea3bdvn+WIESNkuuP8xx9/mP3444/XAM2k6u+8846jfgIFaG6GrVAoBHV1daisrGQGBga8c+fOKgAYPXp0hS5R0xEIBFypVArUajUUCoXAwMCAr1u3zmHRokW3jYyM7rqL9ujRo8u+/vpry/fee6+wuf3dFErOyFMpwqLv4w6BEHIPEydOlH3wwQeOUqnUZ/DgwbJXX321ZMyYMRXV1dVs+vTpPSIjI68OGzZMUVJSIhCLxer33nvPnjGGzMzM1EuXLhm/9NJLblevXr0CACkpKaZJSUkp9vb2qsWLF3cNCgqSfffddzlFRUXCwMBAz/Hjx8vMzc3rk5W9e/d2Tk5ONklLS0vJz88X9e3b1/PFF1+siImJyTY1NQ1IT09PbSrmtLQ0kwsXLqTJ5XJhQECA1+TJk8svXrxokp2dbZyUlJTGOccLL7zgeuTIEXFhYaHIwcGh7sSJE9mAprfF2tpa9dlnn9nHxsZm6iej+iQSSW16enrq3LlznefMmSM9e/ZselVVlcDX19c7PDz8TnOxnzhxolN2drZRdnb2lZs3bxr4+vp6z549u7impoaFhoZKfvnll2xHR0flF198Ybl8+fKu3333XU5zx2b27NndPv744z/HjBlTsXTpUseVK1c67t69+wYAKJVKlpycnPbtt99arF+/3nHUqFF3JZgN9+Hw4cNdp0+fXrxkyZLiTz75xDokJMT52LFjV/W3mTt3rnTLli1/jh49uuJeQ6E6x48fN62rq2NeXl6NJrc/ffq0+K9//WspABQWForMzMxUBgYGAACpVFpbWFjYqBdr9uzZpT/99FNnOzs7/+rqasG77757w97evtnZBSwtLdUvvvhimZeXl9eQIUNkVlZWqoSEhE6bNm1qNLF9v379Kj/88MMu0Myw1GKUnJGn0r7O/R53CISQe7CwsFBfuXIl9ejRo2bR0dFms2bN6rF27dqb/fv3V9jZ2dXpbuBpZWWlBjRfukuWLLkNAAEBAdWOjo61ycnJxgAwZMgQme7L9MSJE+ZRUVGdt27d6gBozifKzs427N27d/1ckvHx8WZTp04tEYlEcHZ2Vvbr16/i5MmTpi4uLuX3inn06NFlYrGYi8Vi5YABA2Tx8fGd4uPjxXFxceZeXl5eAKBQKATp6enGI0aMkL/11lvOISEhXSdMmFDesIepOVOnTi0DAF9fX0VlZaXA0tJSbWlpqTY0NFQXFRUJm4s9Nja2frlUKq0bMGCAHNBMEp+VlWUyfPhwd0DTm2Rra9tsr1lxcbFQLpcLx4wZUwEA8+fPL54yZUp33fopU6aUAsDAgQMrV6xYcd/hukuXLnU6cuTIVQAICQkpWbdu3V3JV1FRkVAulwt1w5Bz5swpjomJsWiuvtzcXIPXX3+9+65du64LhY1GNVFYWGhgb29/33lS9cXGxpoKBAJeUFCQVFRUJBw0aJDHSy+9JPPy8mp2mP29994r1PWGTZs2zeXdd9/N+9e//mVz7Ngxcx8fn6qNGzfmA5oe4cLCQoPWxANQckYIIc+85oYeHzaRSISxY8fKx44dK/fz86uKiIiw7t+/f6vvqm5qalrfK8Y5x8GDB7P9/f0b9aq0VcO5YBlj4Jxj6dKl+StWrGg0T+nFixdTv//+e4s1a9Z0PXbsmOyjjz5q1LPSkLGxMQcAgUAAQ0PD+iEygUCAurq6xpPR3gfnnLm6ulZdvnw5vbXb3is+kUgElUrV6njaoqSkRDB69GjXt99++9aIESOanAXA2NhYXVVVJQAAe3t7pVwuF9bV1cHAwAA5OTmG9vb2jRKuiIgI65EjR5YbGRnxrl27Kp977rmK06dPd7pXcqZz6tQpE845/Pz8qletWtX15MmTWX/961+lycnJRr6+vjVVVVUCY2Nj9f3qaeipPimREEJIx5SYmGiUnJxspHt96dIlEycnp1o/P7/q27dvG8TGxpoCQGlpqaCurg6DBg2q2LdvnxWg6Q3Kz8839PPzq25Yb1BQkGzz5s32arXm+/DUqVMmDcsMHTpUfvDgQSulUom8vDzRuXPnxEOGDLnvlD9HjhzprFAoWEFBgfDMmTNmgwcPrhw9erQsIiLCpry8XAAA169fN7h165YoJyfHwMzMTL1o0aKSsLCwgsuXL5sCQKdOnVS6sg+iudiHDRtWvzw3N9fgzJkzZgDg5+dXXVJSIjp27FgnQNOTmJCQYNxc/dbW1ipzc3PV0aNHxQCwa9cu6wEDBrSo168pAQEBlV9++aUlAOzcudMqMDDwrrpsbGxUZmZmqqioKDEAfPXVV1ZN1VNdXc3GjBnj+sorrxS//vrrpU2VAYCePXtWZ2ZmGgGahLZ///5y3RWpu3fvth47dmxZw20kEknt8ePHzQFAJpMJLl682MnX17fRZ6spq1ev7rpx48a82tpaplarmbZdrrvoIzU11ahnz56tnuOTes4IIYQ8cjKZTBgaGiqRyWRCoVDIpVJpzddff51rbGzMIyMjr4aGhkqqq6sFxsbG6ri4uMzw8PDbwcHBLu7u7l5CoRA7d+7M0V1MoO/DDz/MW7BggcTDw8NLrVYzZ2fnmuPHj2frl5k5c2bZ6dOnxZ6ent6MMb5u3bqbEonkvkNhnp6eioEDB/YsLS0VLV++PF8qldZJpdK6lJQU4+eee84D0PTiRUZGXk9PTzd64403nAQCAUQiEd++fXsuAMyaNato1KhR7vb29rUNLwhoieZinzlzZll0dLS5q6urj6OjY01AQEAFoOnp+uabb66GhoZK5HK5UKVSsZCQkMLAwMBmk489e/ZcDwkJcQkNDRVIJJKaAwcO5LQ2Tp0dO3b8GRwcLN2yZYuD7oKAhmV27dqVM2/ePCljrNkLAnbv3m15/vx5cWlpqWj//v022mXXBw4ceFfiM378+PLPPvvMNiwsrAgANm/efHPatGk93nvvva7e3t6K//u//ysCgMjISIvz5893+uSTT/LCw8Nvv/LKK1JXV1dvzjlee+21on79+lUBwLhx47qdOXPGrLS0VGRvb++3atWqvH/84x9FABAREdE5ICBAIZVK6wDAx8dHob0tTNWAAQOqACAmJsZ87Nix9xwubwrjvNFn+6EJDAzkCQkJj6y91hr57i8PvY2oNWMeehtPAzoWLfOk76eGw0SAZliK3I0xdoFzHtiedSYmJub4+/s3Gooj5EnXp0+fnlFRUdkNr+R81Kqqqlj//v17JiQkpOsuStCXmJho4+/vL21qWxrWJIQQQshTY9OmTTevXr3a6nuLtbfs7GzDf/7zn7eaSszuh4Y1CSGEEPLUGD58+H3PH3wUfH19a3x9fR/owhRKzshTaUbZ2UbL6PYahBBCngSUnJGn0szyc42WUXJGCCHkSUDnnBFCCCGEdCCUnBFCCCGEdCCUnBFCCHksVq5c6eDq6uqtvTeUV0xMTKfHHdPChQudXF1dvRvO8RgWFua4du1a+7bWv379eju5XP7Qv3snT54s1d18tS1lHkRz+1Bfc/szIyPD0M3Nzbvh8szMTEMvLy9PDw8PL1dXV++NGzfaNlf3qFGjuqemphoCmknV3d3dvSQSic/s2bOddTcn1nfnzh3hX/7ylx7u7u5evr6+nufPnzcGAIVCwXx9fT179uzp5erq6v2Pf/zDUbfN+PHju7m7u3stXry4q25ZeHh4l4iIiM661wcOHLBYunSpIx4AnXNGCCHkkTt27FinqKiozsnJyakmJiY8Pz9fVFNT06bpgHTT9LTF/v37bUpLSy+LRA/n63Hnzp328+fPLzEzM2v1lD5PioexDyUSSd2FCxfSTUxMeHl5ucDLy8t76tSpZbobwOokJCQYq1Qqppt6adGiRS6fffZZblBQUOXzzz/vdvDgQfOpU6fedaPb1atXd/Hz81P8/vvvVy9dumS8aNEiyR9//JFpbGzMT548mWFhYaGuqalhzz33XM/o6OhysVisNjExUWdmZqYOHDjQrbi4WFhRUSFISEjopJtTEwCmTZtWvn79+q5yubygtcebkjNCCHnG3VwV3+dh1e304ZAm5+28deuWgZWVlVJ3l/8uXbrU36E/NjbWdOnSpRKFQiEwNDTkcXFxGUZGRjw4ONglKSnJVCgUYuPGjTfGjRsn37p1q/Xhw4ctFQqFQKVSsejo6Ky5c+dK0tPTTZRKJXvrrbfyZsyYUabftlqtRkhIiFNMTIwFY4yvWLEif/78+aXDhw93VSgUQh8fH69ly5blz58//65pgpKSkkx79erlUVpaKgoNDS1YtmxZEQCsWbPG/tChQ1a1tbVszJgxZR9//HGeTCYTjB8/vnt+fr6hWq1m4eHheYWFhQa3b982GDZsmLulpaWy4QwBXbt29Z04cWJJdHS0hUgk4jt27MhdtWpV19zcXKMlS5YUhoeH32kudrVajdmzZ0vi4uLMHR0daw0MDOqTgfj4eNOwsDBnhUIhsLS0VEZGRua4uLg0O/n56dOnTUJCQlyqqqoELi4uNfv378+xtbVV9e3bt2efPn0qTp48aS6Xy4U7duzIaTihe8N9OHTo0MpZs2ZJS0pKRLoZAtzc3O6aszI+Pt503rx5UgDNzhCgm9MT0NzctakeMAD46quvrMeNG1cGaCZJr6ioEOjm4Zw+fXrx4cOHLRsmZxkZGcarVq0qAICAgIDqmzdvGt64cUPk7OystLCwUANAbW0tUyqVjDEGAwMDXlVVJVCpVFAqlQKRSMRXrlzpuH79+jz9egUCAQYOHCj/9ttvLebNm9fslFNNoWFNQgghj9zEiRNleXl5hlKp1GfGjBmSX375RQxo5lCcPn16j08++eTPjIyM1NjY2AyxWKzesGGDHWMMmZmZqfv377+2YMECqUKhYACQkpJi+uOPP149f/58xptvvtklKChIlpycnBYfH5+xevVqJ5lMdtd33d69ezsnJyebpKWlpURHR2euXbvWKTc31yAmJibbyMhInZ6entowMQOAtLQ0k5MnT2acOXMmfdOmTY45OTkGP/zwg3l2drZxUlJSWlpaWurly5dNjxw5Iv7hhx/MHRwc6jIyMlKzsrJSXn75Zdnq1atv29nZ1cXGxmY2N3WTRCKpTU9PT+3Xr1/FnDlzpD/99NPVs2fPpm/YsMHxXrFHRER0zs7ONsrOzr6yf//+6xcvXhQDmrk0Q0NDJT/++OPVlJSUtFmzZhUtX768a1Nt68yePbvb+++/fzMzMzPV29u7auXKlfVDc0qlkiUnJ6dt2LDhxvr16xsN2TXchyEhIZLp06cXZ2Zmpk6bNq04JCTEueE2c+fOleqO973iys7ONnB3d/fq1q2bX2hoaEHDXjMAOHv2rLh///4KQJOcdenSpb6Mi4tLbX5+fqOuVR8fn6rvvvvOEgCOHz9ump+fb5STk2Oofb/w8PDwsre39x82bJhs+PDhlb179662sbFRent7e40ePbosJSXFSK1WY/DgwYqGdQcGBlbGx8eL7/W+mkLJGSGEkEfOwsJCfeXKldR///vfuba2tspZs2b12Lp1q3VSUpKxnZ1d3bBhwxQAYGVlpTYwMMDp06fFM2fOLAY0vRuOjo61ycnJxgAwZMgQmb29vQoATpw4Yf7xxx938fDw8Bo8eHDPmpoalp2dfdfd4uPj482mTp1aIhKJ4OzsrOzXr1/FyZMnTe8X8+jRo8vEYjHv0qWLcsCAAbL4+PhOR48eNY+LizP38vLy8vb29rp69apxenq6ce/evavi4+PNQ0JCuh49elRsbW3doqmEpk6dWgYAvr6+it69e1daWlqqHR0dlYaGhuqioiJhc7HHxsbWL5dKpXUDBgyQA5pJ4rOyskyGDx/u7uHh4bVp06YueXl5zY79FhcXC+VyuXDMmDEVADB//vziM2fO1CcXU6ZMKQWAgQMHVt68efO+d+G/dOlSpwULFpQAQEhISMmFCxfuSlSKioqEcrlcOHr06AoAmDNnTnFzdbm6utZlZmampqWlXdm/f7/NjRs3Go3+3blzx8DBwaHZXsGmrF+/Pr+8vFzo4eHhtWXLFnsPDw+FUCjkACASiZCenp76559/Jl28eLGT7ny03bt330hPT09dt25doW7y85UrVzq89NJL3Tdv3myjq9vBwUFZUFDQ6tkKaFiTEEKecc0NPT5sIpEIY8eOlY8dO1bu5+dXFRERYa3r9WgNU1PT+jEuzjkOHjyY7e/v/0B3Zr+XhnPBMsbAOcfSpUvzV6xY0Wie0osXL6Z+//33FmvWrOl67Ngx2UcffZTfsExDuuE7gUAAQ0PD+qE8gUCAurq6Vp+Txzlnrq6uVZcvX05v7bb3ik8kEkGlUrXpHMEHJZVK6zw8PKqOHTtm9vrrr9/Vw2lkZKSuqqoSAICLi0udfk9Zbm6uoX5Pmo6VlZX64MGDOYBmyNvZ2dnXw8Pjrs+PjY2NasiQIfKffvrJ4rnnnqufNH7fvn2de/XqpZDJZIJr164Z//rrr9cGDx7stmDBghIzMzN1VVUVMzY2bvX5hW3qOWOM/YMxlsIYu8IYO8AYM25LfYQQQp4NiYmJRsnJyUa615cuXTJxcnKq9fPzq759+7ZBbGysKQCUlpYK6urqMGjQoIp9+/ZZAZreoPz8fEM/P7/qhvUGBQXJNm/ebK87J+nUqVMmDcsMHTpUfvDgQSulUom8vDzRuXPnxEOGDLnvlD9HjhzprFAoWEFBgfDMmTNmgwcPrhw9erQsIiLCpry8XAAA169fN7h165YoJyfHwMzMTL1o0aKSsLCwgsuXL5sCQKdOnVS6sg+iudiHDRtWvzw3N9fgzJkzZgDg5+dXXVJSIjp27FgnQDPMmZCQ0Ox3tbW1tcrc3Fx19OhRMQDs2rXLesCAARXNlb+fgICAyi+//NISAHbu3GkVGBh4V102NjYqMzMzVVRUlBgAvvrqK6um6rl69apBRUUFAzRXV54/f17s7e3d6Pi7ublVp6WlGQGa5EwsFqujo6M7qdVqREZGWk+YMKGs4TZFRUXC6upqBgAff/yxTd++feVWVlbqvLw8UVFRkRAAKioq2PHjx809PT3r26ypqWHbtm2zW7duXUFlZaWAMcYBQK1WM93FLRkZGcbe3t5Vrd1vD9xzxhjrCiAUgBfnvIox9h8ArwD46kHrJIQQ8myQyWTC0NBQiUwmEwqFQi6VSmu+/vrrXGNjYx4ZGXk1NDRUUl1dLTA2NlbHxcVlhoeH3w4ODnZxd3f3EgqF2LlzZ47uYgJ9H374Yd6CBQskHh4eXmq1mjk7O9ccP348W7/MzJkzy06fPi329PT0ZozxdevW3ZRIJMqGdTXk6empGDhwYM/S0lLR8uXL86VSaZ1UKq1LSUkxfu655zwATS9eZGTk9fT0dKM33njDSSAQQCQS8e3bt+cCwKxZs4pGjRrlbm9vX9vceWf30lzsM2fOLIuOjjZ3dXX1cXR0rAkICKgAND1d33zzzdXQ0FCJXC4XqlQqFhISUhgYGNgosdHZs2fP9ZCQEJfQ0FCBRCKpOXDgQE5r49TZsWPHn8HBwdItW7Y46C4IaFhm165dOfPmzZMyxpq9ICApKclk5cqVTrreysWLFxf07du3UdIzevTospiYGLOJEyfKAeDTTz/NnTt3brfq6moWFBQkmzJlSjkA6G7FER4efufy5cvG8+bN6wYA7u7uVZGRkTkAcOPGDYPZs2d3U6lU4JyzCRMmlLz66qvlurY2bNhgO3369GIzMzN1v379qqqqqgTu7u5eI0aMKLexsVEBQFxcnNmGDRtutXa/Mc4bfbZbtqEmOTsDwB+ADMBhAFs55781t01gYCBPSEh4oPYehZHv/vLQ24haM+aht/E0aOuxiMrd1rhOlyV3l3kKjsWT/pltOEwEaIalyN0YYxc454HtWWdiYmKOv79/o6E4Qp5kFRUVbNCgQT0vXLiQ/rBuh9JSN27cEE2dOrX7H3/80WQSnpiYaOPv7y9tat0DR845v8UY+wjAnwCqAPzWVGLGGFsAYAEASCSSB22OkCfOo0icHoWn5X0QQp5+YrGYr127Nu/69euGDW/Z8ahdu3bNcPPmzTceZNu2DGtaApgAoBuAMgDfMcZmcM736ZfjnH8O4HNA03P2oO0RQgghhNzP5MmTmxwafdR0Vxw/iLZcEPACgOuc8zuc8zoAPwAY2Ib6CCGEEEKeeW1Jzv4E0J8xZso0J46MAJDWPmERQgghhDybHjg545yfBXAQwEUAydq6Pm+nuAghhBBCnkltupSBc/42gLfbKRZCCCGEkGceTd9EnkojXZY0ehBCOpaVK1c6uLq6eru7u3t5eHh4xcTEdHrcMS1cuNDJ1dXVe+HChU76y8PCwhzXrl1r39b6169fbyeXyx/6d+/kyZOle/bssWxrmQfR3D7U19z+zMjIMHRzc/NubruSkhKBvb29X3BwcLO3fxg1alT31NRUQ0Azqbq7u7uXRCLxmT17tnNTE6YXFxcLhw8f7tqzZ08vV1dX7y1btljr1mVlZRkOGjTIrXv37t49evTwzsjIMASA8ePHd3N3d/davHhx/Tyl4eHhXSIiIjrrXh84cMBi6dKljeYfbQmavokQQsgjd+zYsU5RUVGdk5OTU01MTHh+fr5Id1f1B1VXVwcDg2anjWyR/fv325SWll5+WPfI2rlzp/38+fNLzMzMWj2lz5PiYe7DZcuWde3bt6+8ufUJCQnGKpWKeXl51QLAokWLXD777LPcoKCgyueff97t4MGD5lOnTr3ras5NmzbZ9uzZsyomJiY7Ly9P5Onp6bNw4cISY2NjPn369G5vvPFG/qRJk2Tl5eUCgUCAs2fPmpiYmKgzMzNTBw4c6FZcXCysqKgQJCQkdNq4cWP9FF3Tpk0rX79+fVe5XF7Q2uNNyRkhhDzjNk8b2+dh1b3s25+bnLfz1q1bBlZWVkrdXf67dOlSf4f+2NhY06VLl0oUCoXA0NCQx8XFZRgZGfHg4GCXpKQkU6FQiI0bN94YN26cfOvWrdaHDx+2VCgUApVKxaKjo7Pmzp0rSU9PN1Eqleytt97KmzFjRpl+22q1GiEhIU4xMTEWjDG+YsWK/Pnz55cOHz7cVaFQCH18fLyWLVuWP3/+/LvmbUxKSjLt1auXR2lpqSg0NLRg2bJlRQCwZs0a+0OHDlnV1tayMWPGlH388cd5MplMMH78+O75+fmGarWahYeH5xUWFhrcvn3bYNiwYe6WlpbKhjMEdO3a1XfixIkl0dHRFiKRiO/YsSN31apVXXNzc42WLFlSGB4efqe52NVqNWbPni2Ji4szd3R0rDUwMKhPBuLj403DwsKcFQqFwNLSUhkZGZnj4uLS7OTgp0+fNgkJCXGpqqoSuLi41Ozfvz/H1tZW1bdv3559+vSpOHnypLlcLhfu2LEjZ9SoUXdNx9RwHw4dOrRy1qxZ0pKSEpFuhoCG9x+Lj483nTdvnhRAszME6MrduXPH4MUXXyxPSEhospf1q6++sh43blwZAOTm5hpUVFQIRowYUQkA06dPLz58+LBlw+SMMQa5XC5Uq9WQyWQCCwsLpYGBAb9w4YKxSqXCpEmTZABgYWGhBgADAwNeVVUlUKlUUCqVApFIxFeuXOm4fv36PP16BQIBBg4cKP/2228t5s2bd9dn6X5oWJMQQsgjN3HiRFleXp6hVCr1mTFjhuSXX34RA0B1dTWbPn16j08++eTPjIyM1NjY2AyxWKzesGGDHWMMmZmZqfv377+2YMECqUKhYACQkpJi+uOPP149f/58xptvvtklKChIlpycnBYfH5+xevVqJ5lMdtd33d69ezsnJyebpKWlpURHR2euXbvWKTc31yAmJibbyMhInZ6entowMQOAtLQ0k5MnT2acOXMmfdOmTY45OTkGP/zwg3l2drZxUlJSWlpaWurly5dNjxw5Iv7hhx/MHRwc6jIyMlKzsrJSXn75Zdnq1atv29nZ1cXGxmY2N3WTRCKpTU9PT+3Xr1/FnDlzpD/99NPVs2fPpm/YsMHxXrFHRER0zs7ONsrOzr6yf//+6xcvXhQDmvkfQ0NDJT/++OPVlJSUtFmzZhUtX768a1Nt68yePbvb+++/fzMzMzPV29u7auXKlfVDc0qlkiUnJ6dt2LDhxvr16xsN2TXchyEhIZLp06cXZ2Zmpk6bNq04JCTEueE2c+fOleqOd3MxqVQqLFu2zHnLli33vKnr2bNnxf3791cAmuRMf6JzFxeXWv2J0HXCw8NvZ2VlGdvb2/v17t3be+PGjTeEQiFSU1ONzc3NVS+++GIPT09Pr4ULFzoplUr07t272sbGRunt7e01evTospSUFCO1Wo3Bgwc3uq9ZYGBgZXx8vPheMTeFkjNCCCGPnIWFhfrKlSup//73v3NtbW2Vs2bN6rF161brpKQkYzs7uzrdDTytrKzUBgYGOH36tHjmzJnFABAQEFDt6OhYm5ycbAwAQ4YMkdnb26sA4MSJE+Yff/xxFw8PD6/Bgwf3rKmpYdnZ2Yb6bcfHx5tNnTq1RCQSwdnZWdmvX7+KkydPmt4v5tGjR5eJxWLepUsX5YABA2Tx8fGdjh49ah4XF2fu5eXl5e3t7XX16lXj9PR04969e1fFx8ebh4SEdD169KjY2tpa1ZL9MnXq1DIA8PX1VfTu3bvS0tJS7ejoqDQ0NFQXFRUJm4s9Nja2frlUKq0bMGCAHNBMEp+VlWUyfPhwdw8PD69NmzZ1ycvLa3bst7i4WCiXy4VjxoypAID58+cXnzlzpj65mDJlSikADBw4sPLmzZuGzdWjc+nSpU4LFiwoAYCQkJCSCxcu3JWoFBUVCeVyuXD06NEVADBnzpzipurZsGGD7YsvvljWo0ePZnv8AODOnTsGDg4O9yzT0OHDhy18fHyqCgsLk86dO5e6bNkySUlJiUCpVLKEhATxJ598ciMpKSk1JyfHaNu2bTYAsHv37hvp6emp69atK1y9enXXjRs35q1cudLhpZde6r5582YbXd0ODg7KgoKC++6nhmhYkxBCnnHNDT0+bCKRCGPHjpWPHTtW7ufnVxUREWGt6/VoDVNT0/ohPM45Dh48mO3v71/TvtE2ngtWNwn30qVL81esWNFontKLFy+mfv/99xZr1qzpeuzYMdlHH32U37BMQ8bGxhzQDIkZGhrWz6ojEAhQV1fX6nPyOOfM1dW16vLly+mt3fZe8YlEIqhUqjadI9gaZ86cEZ8/f168Z88eO4VCIairqxOIxWLV9u3b75pU3MjISF1VVSUAABcXlzr9nrLc3FxD/Z40na+//tp61apVBQKBAD4+PjXOzs41iYmJxhKJpNbDw6NKd/7a+PHjS/UTVQDYt29f5169eilkMpng2rVrxr/++uu1wYMHuy1YsKDEzMxMXVVVxYyNjVt9fiH1nBFCCHnkEhMTjZKTk410ry9dumTi5ORU6+fnV3379m2D2NhYUwAoLS0V1NXVYdCgQRX79u2zAjS9Qfn5+YZ+fn7VDesNCgqSbd682V53Vd6pU6dMGpYZOnSo/ODBg1ZKpRJ5eXmic+fOiYcMGVJ5v5iPHDnSWaFQsIKCAuGZM2fMBg8eXDl69GhZRESETXl5uQAArl+/bnDr1i1RTk6OgZmZmXrRokUlYWFhBZcvXzYFgE6dOql0ZR9Ec7EPGzasfnlubq7BmTNnzADAz8+vuqSkRHTs2LFOgGaYMyEhwbi5+q2trVXm5uaqo0ePigFg165d1gMGDKhorvz9BAQEVH755ZeWALBz506rwMDAu+qysbFRmZmZqaKiosQA8NVXX1k1Vc9///vf6/n5+cm3bt1KXrdu3c2XX365uGFiBgBubm7VaWlpRoAmOROLxero6OhOarUakZGR1hMmTChruE3Xrl1rf/vtN3NAM1n5tWvXjD08PGqHDRtWKZPJhHl5eSIAOH78uLmXl1eVbruamhq2bds2u3Xr1hVUVlYKGGMcANRqNdNd3JKRkWHs7e1d1bDN+6GeM0IIIY+cTCYThoaGSmQymVAoFHKpVFrz9ddf5xobG/PIyMiroaGhkurqaoGxsbE6Li4uMzw8/HZwcLCLu7u7l1AoxM6dO3N0FxPo+/DDD/MWLFgg8fDw8FKr1czZ2bnm+PHj2fplZs6cWXb69Gmxp6enN2OMr1u37qZEIlE2rKshT09PxcCBA3uWlpaKli9fni+VSuukUmldSkqK8XPPPecBaHrxIiMjr6enpxu98cYbTgKBACKRiG/fvj0XAGbNmlU0atQod3t7+9rmzju7l+ZinzlzZll0dLS5q6urj6OjY01AQEAFoOnp+uabb66GhoZK5HK5UKVSsZCQkMLAwMBGia3Onj17roeEhLiEhoYKJBJJzYEDB3JaG6fOjh07/gwODpZu2bLFQXdBQMMyu3btypk3b56UMXbPCwJaYvTo0WUxMTFmEydOlAPAp59+mjt37txu1dXVLCgoSDZlypRyANi4caMtAISHh9/55z//mT99+nSpu7u7F+ecvfPOOzd1F6h8+OGHN59//nl3QDPU/I9//KO+h3TDhg2206dPLzYzM1P369evqqqqSuDu7u41YsSIchsbGxUAxMXFmW3YsKFREnk/jPNHNxd5YGAgT0hIeGTttdbId3956G1ErRnz0Nt4GrT1WETlbmtcZ4N7nT3sY/EoPk9Put/Wjm207FH+TXpSMMYucM4D27POxMTEHH9//0ZDcYQ8ySoqKtigQYN6XrhwIf1h3Q6lpW7cuCGaOnVq9z/++KPJJDwxMdHG399f2tQ6GtYkhBBCyFNBLBbztWvX5l2/fr3VJ+G3t2vXrhlu3rz5nleXNoeGNQkhhBDy1Jg8eXKbhkbbi+6K4wdByRl5ZtGwIyGEkI6IhjUJIYQQQjoQSs4IIYQQQjoQSs4IIYQ8FitXrnRwdXX1dnd39/Lw8PCKiYlpcr7ER2nhwoVOrq6u3gsXLnRqj/qOHj0qdnV19fbw8PC6fv26wahRo7oDmvkrv/32W4umttm6dat1cHCwpK1tb9261TonJ6dtM8G3QFhYmOPatWvt21qG/A+dc0YIIeSRO3bsWKeoqKjOycnJqSYmJjw/P1+ku3Hng6qrq4OBQdtykf3799uUlpZevtdtGFrTzt69e63CwsLyFy1aVAIAR48evQYACQkJpgkJCZ2mTZtW3qaA72Hfvn02vXr1qpJKpa2azog8ftRzRgghzzDGWJ+H/Wiq3Vu3bhlYWVkpdTeS7dKli1KXRMTGxpoGBAR49OzZ08vX19eztLRUoFAo2F//+lepu7u7l6enp9dPP/1kBmh6h4YPH+7av39/94EDB/aUyWSCKVOmSH19fT09PT299u3b17lh22q1GgsXLnRyc3Pzdnd39/riiy8sAWD48OGuCoVC6OPjU79MJywszHHixIndevfu7fHyyy93y8vLE40cObKHj4+Pp4+Pj+dvv/3WqNfvX//6l80vv/xi9c9//rPr+PHju2VkZBi6ubl5V1dXsw8++MDxp59+svTw8GjUlm7/9O3bt6eLi4vPsmXLuuiWb9++3crX19fTw8PD67XXXnNRKpVQKpWYPHmyVPd+1q1bZ7dnzx7LK1eumAYHB3f38PDwqqiouCvx7du3b8+5c+c6+/j4eHbv3t07NjbW9MUXX+zh4uLiExoaWj+h+TvvvGPv5ubm7ebm5r1+/Xo73fKVK1c6SKVSnz59+vTMysqqn+khJSXFaMiQIW7e3t6effr06Xnp0qVmZyMgzaOeM0IIIY/cxIkTZR988IGjVCr1GTx4sOzVV18tGTNmTEV1dTWbPn16j8jIyKvDhg1TlJSUCMRisfq9996zZ4whMzMz9dKlS8YvvfSS29WrV68AQEpKimlSUlKKvb29avHixV2DgoJk3333XU5RUZEwMDDQc/z48TJzc/P6+Q337t3bOTk52SQtLS0lPz9f1LdvX88XX3yxIiYmJtvU1DQgPT09tamYs7KyjM+ePZsuFov5uHHjuoWFhRWOHDmyIisry3DkyJFu165dS9EvHxYWVnTq1Cnx2LFjy19//fXSjIwMQ0Bz1/433ngjLyEhodPevXv/bKqtpKSkTsnJySlisVgdEBDgNWHChHKxWKw+ePCgVUJCQrqRkRGfMWOGZMeOHdb+/v5V+fn5BllZWSmAZjJxGxsb1WeffWb30Ucf3Rg6dGiTt3QwNDRUX7lyJe3dd9+1mzJliuv58+fT7OzslFKp1PfNN98szMrKMtq/f7/1hQsX0jjn6NOnj+eIESPkarWaHTp0yCo5OTm1rq4OvXr18goICFAAwLx581w+//zzXF9f35qYmJhOISEhkjNnzrR6JoRnHSVnhBBCHjkLCwv1lStXUo8ePWoWHR1tNmvWrB5r16692b9/f4WdnV2d7h5RVlZWagA4ffq0eMmSJbcBICAgoNrR0bE2OTnZGACGDBkis7e3VwHAiRMnzKOiojpv3brVAdDMf5idnW3Yu3fv+umK4uPjzaZOnVoiEong7Oys7NevX8XJkydNXVxc7jnEOGrUqDKxWMwB4NSpU+ZZWVn183ZWVFQIy8vLBRYWFq2e5LopgwcPljk4OKgAYMyYMaUnTpwQi0QifuXKFVN/f39PAKiurhbY2dkpp02bVnbjxg2jWbNmOY8bN6580qRJLbrP16RJk8oAwN/fv8rV1bXKxcWlDgCcnZ1rrl27ZnjixAnxSy+9VKZLbMeMGVN6/PhxM7VajZdeeqnMzMxMDQAvvvhiGQCUl5cLLl26JJ4yZUoPXRu1tbWPbHL0pwklZ4QQQh4LkUiEsWPHyseOHSv38/OrioiIsO7fv3+rb9xpampanxBxznHw4MFsf3//mvaNFujUqdNd7Vy8eDHN1NT0rvnGBg8e7FZUVGTg7+9f+e233+Y+aFuMsUavOedsypQpxZ9++mmjuRqvXLmSeujQIfMdO3bYfvvtt1bfffddzv3aMDY25gAgEAhgZGRU/z4EAgGUSmWrkyqVSgUzMzNlcz2PpOXonDNCCCGPXGJiolFycnL9uUqXLl0ycXJyqvXz86u+ffu2QWxsrCkAlJaWCurq6jBo0KCKffv2WQFAUlKSUX5+vqGfn1+jybuDgoJkmzdvtlerNXnUqVOnTBqWGTp0qPzgwYNWSqUSeXl5onPnzomHDBlS2Zr4Bw8eLPvggw/qz8E6ffq0CQCcPHkyKz09PfV+iZm5ubmqoqKi2e/gkydPmhcWFgorKirYr7/+2nnYsGEVo0aNkv3888+Wt27dEgFAYWGhMDMz0zA/P1+kUqkwe/bssg8++OBWcnKyKQCIxWJVeXm5sDXvS19QUFDFr7/+2lkulwtkMpng119/tQwKCpIPHz684tdff+1cUVHBSktLBb///ntnQNPL6eTkVLt7925LQHNu3x9//NFo/5P7o54zQgh5hnHOLzyOdmUymTA0NFQik8mEQqGQS6XSmq+//jrX2NiYR0ZGXg0NDZVUV1cLjI2N1XFxcZnh4eG3g4ODXdzd3b2EQiF27tyZo7uYQN+HH36Yt2DBAomHh4eXWq1mzs7ONcePH8/WLzNz5syy06dPiz09Pb0ZY3zdunU3JRKJsjXxf/755zfmzZsncXd391KpVKxfv37ygQMHNnn+WFNGjx4t/+ijj7p4eHh4LVu2LH/+/Pml+uv9/Pwqx48f36OgoMDwr3/9a7HuvLHVq1ffGjFihLtarYaBgQHfunXrn6ampuq5c+dK1Wo1A4D169ffBIDg4OCiJUuWuKxYsUKdkJCQphuSbanBgwcrXnvtteLevXt7AsDMmTPvDBo0qAoAJk2aVOLj4+NtbW1d5+fnV5/YHjhw4Nr8+fNdNmzY0EWpVLJJkyaVDBgwoKo17RKAcd6qY9UmgYGBPCEh4ZG111qPYjqfqDVjHnobT4O2Houo3G2N63RZ0qY6Sfv7be3YRsse5d+kJwVj7ALnPLA960xMTMzx9/cvas86CSEtl5iYaOPv7y9tah0NaxJCCCGEdCCUnBFCCCGEdCBtSs4YY50ZYwcZY+mMsTTG2ID2CowQQggh5FnU1gsCtgA4yjn/K2PMEIBpO8RESJtFWPR93CEQQgghD+SBkzPGmAWAoQBmAwDnvBZAbfuERUjb7Ovc73GHQAghhDyQtgxrdgNwB8AextglxtiXjLFGc4sxxhYwxhIYYwl37txpQ3OEEEIIIU+/tgxrigD0BrCEc36WMbYFwCoAa/QLcc4/B/A5oLmVRhvaI4QQ8pCMfPeXJicof1BRa8a06P5pERERnYODg3tcvHgxJSAgoBoAMjIyDMeOHeuWlZWV8vPPP5tt3rzZvuG9ytqTfnttKUNIe2lLz9lNADc552e1rw9Ck6wRQgghLfLNN99Y9e7du2Lv3r1WjzuWjqquru5xh0AesQdOzjjnBQBuMMZ6aheNAEDzaRFCCGmR8vJywfnz58V79uzJOXToUKuSs61bt1q/8MILPQYOHOjWtWtX3/fff9/2nXfesff09PTy9/f3KCwsFAKaaZX8/f093N3dvf7yl7/0uHPnjhAA4uPjTXv27OnVs2dPr3/961/10zAplUosXLjQycfHx9Pd3d1r06ZNNg3bTkhIMPb19fX08PDwcnd399KfhkpXx+TJk6Vubm7e7u7uXuvWrbMDgCtXrhgNHDjQvWfPnl5eXl6eKSkpRmq1GgsXLnTSlf3iiy8sAeDnn38269OnT8/hw4e7urm5+TQXV25urkFgYGBPDw8PLzc3N++jR4+KW3scSMfT1vucLQEQyRhLAtALwPttjogQQsgzYf/+/Z2ff/75cj8/vxpLS0tlfHx8q674z8zMNPnll1+unj9/Pu2DDz7oampqqk5LS0sNDAys3LlzpzUAzJ49u9v7779/MzMzM9Xb27tq5cqVjgAwd+5c6SeffPJnRkbGXZ0Kn3zyiY2FhYXqypUraYmJiWlff/21bXp6uqF+mW3bttkuWrSoMD09PTUpKSmtW7dud10M98cff5jm5+cbZGVlpWRmZqb+/e9/LwaA1157rdvf/va32xkZGakJCQnpEomkbu/evZ2Tk5NN0tLSUqKjozPXrl3rlJubawAAqampptu3b/8zJyfnSnNx7d6922rEiBHl6enpqWlpaSn9+vVr9cTxpONpU3LGOb/MOQ/knPtxzidyzkvvvxUhhBAC/Oc//7F69dVXSwFg8uTJJREREa3qPRs4cKDc0tJS7ejoqBSLxaopU6aUAYCvr68iJyfHqLi4WCiXy4VjxoypAID58+cXnzlzRlxUVCSUy+XC0aNHVwDAnDlzinV1Hjt2zPw///mPtYeHh1dAQIBnaWmpKDU11Vi/3QEDBlRu3ry5y1tvveWQlZVl2HDOSg8Pj5obN24YzZo1y/ngwYPmlpaWqtLSUkFhYaFhcHBwGQCYmppyMzMzdXx8vNnUqVNLRCIRnJ2dlf369as4efKkKaCZX9PDw6P2XnH179+/8sCBAzZhYWGO586dM7G0tFS37iiQjogmPidPpRllZxsto9trENJxFBYWCs+cOWOWkZFhsnjxYqhUKsYY42q1+mZL6zA0NKxPigQCAYyNjbnuuVKpZA8SF+ecbd68+c/JkyfL9JdnZGTU95797W9/KxkyZEjloUOHLMaOHeu2bdu23PHjx8t1621tbVVXrlxJPXTokPmOHTtsv/32W6vPP/+8xZOi65iamtYnWs3FBQBxcXEZ33//vcWcOXO6LV68uHDx4sXFDcuQJwtN30SeSjPLzzV6EEI6joiICMtJkyaV5OXlJd+6dSu5oKAgycnJqTYqKqrdzpmytrZWmZubq3TnYe3atct6wIABFTY2NiozMzOVrq2vvvqqvsfuL3/5S/lnn31mW1NTwwAgKSnJSCaT3fVdmZqaaujp6VmzevXq2yNHjiy7fPmyif76/Px8kUqlwuzZs8s++OCDW8nJyaaWlpZqBweH2oiIiM4AUFVVxeRyuWDo0KHygwcPWimVSuTl5YnOnTsnHjJkSGXD99JcXJmZmYZOTk51y5YtKwoODr5z8eJFuhn8U4B6zgghhLT41hft5bvvvrNasWJFgf6yCRMmlO7bt89q7dq1Bc1t11p79uy5HhIS4hIaGiqQSCQ1Bw4cyAGAXbt25cybN0/KGMPzzz9f3xv1j3/8oygnJ8fI19fXk3POrKys6n799der+nXu27fP6j//+Y+1SCTitra2de+++26+/vqcnByDuXPnStVqNQOA9evX39Rud33+/Pku7777rqOBgQH/7rvvrs6cObPs9OnTYk9PT2/GGF+3bt1NiUSiTEpKuut9NBdXVFSU2datWx1EIhE3NTVVRUZGXm+vfUceH8b5o7v1WGBgIE9ISHhk7bXWyHd/eehtRK0Z89DbeBq09VhE5W5rXKfLkjbVSdrfb2vHNlr2KP8mPSkYYxc454HtWWdiYmKOv79/UXvWSQhpucTERBt/f39pU+toWJMQQgghpAOh5IwQQgghpAOh5IwQQp5Nat05UYSQR0v7u9fsbU8oOSOEkGfTlTt37lhQgkbIo6VWq9mdO3csAFxprgxdrUkIIc8gpVI5r6Cg4MuCggIf0D/qhDxKagBXlErlvOYKUHJGCCHPoD59+twGMP5xx0EIaYz+WyKEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UAoOSOEEEII6UBohgDyVBrpsuRxh0AIIYQ8EOo5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQCg5I4QQQgjpQNqcnDHGhIyxS4yxn9sjIEIIIYSQZ1l73Ofs/wCkATBvh7oIaRdRudsaLaN7nxFCCHkStKnnjDHmBGAMgC/bJxxCCCGEkGdbW4c1PwEQDkDdXAHG2ALGWAJjLOHOnTttbI4QQggh5On2wMkZY2wsgNuc8wv3Ksc5/5xzHsg5D7S1tX3Q5gghhBBCnglt6TkbBGA8YywHwDcAhjPG9rVLVIQQQgghz6gHTs44529wzp0451IArwCI4ZzPaLfICCGEEEKeQXSfM0IIIYSQDqQ9bqUBzvkJACfaoy5CCCGEkGcZ9ZwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQg7TJ9EyEdTYRF38cdAiGEEPJAnpjkbOS7vzzuEIjWk3As9nXu97hDIIQQQh4IDWsSQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQglJwRQgghhHQgT8ytNAhpjRllZxstexZurzFAdb7++R/C59pcX+LgrvXP/U/eanN9APDilc/qn//WDvVFx/Sofz5i+NV2qLH93VwVX//c6cMhjzESQsiTgJIz8lSaWX6u0bJnITkjhBDy5KNhTUIIIYSQDoSSM0IIIYSQDoSSM0IIIYSQDoSSM0IIIYSQDoSSM0IIIYSQDuSBkzPGmDNj7DhjLJUxlsIY+7/2DIwQQggh5FnUlltpKAEs45xfZIyZAbjAGPudc57aTrERQgghhDxzHrjnjHOezzm/qH0uB5AGoOu9tyKEEEIIIffSLjehZYxJAQQAaHRbdsbYAgALAEAikbRHc0+0ke/+8lDrj1oz5qHWTwghhJCHq80XBDDGxAC+B7CUcy5ruJ5z/jnnPJBzHmhra9vW5gghhBBCnmptSs4YYwbQJGaRnPMf2ickQgghhJBnV1uu1mQAdgFI45z/q/1CIoQQQgh5drWl52wQgJkAhjPGLmsfL7VTXIQQQgghz6QHviCAc34SAGvHWAghhBBCnnk0QwAhhBBCSAdCyRkhhBBCSAdCyRkhhBBCSAfSLjehJaSjGemy5HGHQAghhDwQ6jkjhBBCCOlAKDkjhBBCCOlAKDkjhBBCCOlAKDkjhBBCCOlAKDkjhBBCCOlAKDkjhBBCCOlAKDkjhBBCCOlA6D5n5KkUlbut0TK69xkhhJAnAfWcEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IJScEUIIIYR0IG1KzhhjoxhjGYyxbMbYqvYKihBCCCHkWfXAyRljTAjgUwCjAXgBeJUx5tVegRFCCCGEPIva0nPWF0A25/wa57wWwDcAJrRPWIQQQgghzybGOX+wDRn7K4BRnPN52tczAfTjnC9uUG4BgAXalz0BZDx4uA+dDYCixx1ECzwpcQJPTqxPSpwAxfowdPQ4XTjnto87CELIoyF62A1wzj8H8PnDbqc9MMYSOOeBjzuO+3lS4gSenFiflDgBivVheFLiJIQ8G9oyrHkLgLPeayftMkIIIYQQ8oDakpydB+DGGOvGGDME8AqA/7ZPWIQQQgghz6YHHtbknCsZY4sBRAEQAtjNOU9pt8gejydi+BVPTpzAkxPrkxInQLE+DE9KnISQZ8ADXxBACCGEEELaH80QQAghhBDSgVByRgghhBDSgTwTyVlLpplijE1ljKUyxlIYY/v1ls9ijGVpH7M6eKwqxthl7eOhXpxxvzgZYx/rxZLJGCvTW9eh9ul9Yn1k+7SFsUoYY8cZY5cYY0mMsZf01r2h3S6DMTayI8bJGJMyxqr09umOhxlnC2N1YYxFa+M8wRhz0lv3SD+rhBACAOCcP9UPaC5WuAqgOwBDAIkAvBqUcQNwCYCl9rWd9qcVgGvan5ba55YdMVbt84qOsk8blF8CzQUjHXKfNhfro9ynrTj+nwMI0T73ApCj9zwRgBGAbtp6hB0wTimAKx1sn34HYJb2+XAAEY/js0oPetCDHrrHs9Bz1pJppuYD+JRzXgoAnPPb2uUjAfzOOS/RrvsdwKgOGuuj1Nqpu14FcED7vCPu0+ZifdRaEisHYK59bgEgT/t8AoBvOOc1nPPrALK19XW0OB+1lsTqBSBG+/y43vpH/VklhBAAz8awZlcAN/Re39Qu0+cOwJ0xdooxdoYxNqoV27antsQKAMaMsQTt8omPOU4AmiEjaHpydF9+HXGfAmgyVuDR7VOgZbG+A2AGY+wmgF+h6elr6bbtpS1xAkA37XBnLGNsyEOKUaclsSYCeFn7fBIAM8aYdQu3JYSQdvfQp296QoigGS58HpqZDuIYY76PNaLmNRkr57wMmvn3bjHGugOIYYwlc86vPr5QAWhuTnyQc656zHG0RFOxdrR9+iqArzjnmxljAwBEMMZ8HmM8zWkuznwAEs55MWOsD4DDjDFvzrnsMca6HMC/GWOzAcRBM9PJk/B5JYQ8pZ6FnrOWTDN1E8B/Oed12iGhTGgSoEc9RVVbYgXn/Jb25zUAJwAEPMY4dV7B3cOEHXGf6jSM9VHuU6Blsc4F8B9tTH8AMIZm0u5HuV8fOE7tsGuxdvkFaM4Hc39IcbYoVs55Huf8Zc55AIC3tMvKWrItIYQ8FI/7pLeH/YCmp+kaNMNVuhOCvRuUGQXga+1zG2iGMqyhORH4OjQnA1tqn1t10FgtARjpLc/CPU58f9hxast5AMiB9mbH2mUdbp/eI9ZHtk9bcfyPAJitfe4JzblcDIA37r4g4Boe3gUBbYnTVhcXNCfp33rcx197bAXa5/8EsP5xfFbpQQ960EP3eOwBPJI3CbwETQ/TVQBvaZetBzBe+5wB+BeAVADJAF7R23YONCdXZwN4vaPGCmCg9nWi9ufcxxmn9vU7AD5sYtsOtU+bi/VR79MWHn8vAKe0MV0G8KLetm9pt8sAMLojxglgMoAU7bKLAMZ1gH36V2gS70wAX0KbkD+Ozyo96EEPenDOafomQgghhJCO5Fk454wQQggh5IlByRkhhBBCSAdCyRkhhBBCSAdCyRkhhBBCSAdCyRkhhBBCSAdCyRkhbcAYkzLGrjzuOAghhDw9KDkjzwTGGE1VRggh5IlAyRnpkBhjnRhjvzDGEhljVxhj07TLn2OMndYuP8cYM2OMGTPG9jDGkrUTagdpy85mjP2XMRYDIFpb527tdpcYYxOaaPcbxtgYvddfMcb+qu0hi2eMXdQ+Bjax7WzG2L/1Xv/MGHte+/xFxtgf2m2/Y4yJ232nEUIIeSpQbwLpqEYByOOcjwEAxpgFY8wQwLcApnHOzzPGzAFUAfg/AJxz7ssY8wDwG2NMN19jbwB+nPMSxtj7AGI453MYY50BnGOMHeOcV+q1+y2AqQB+0bY3AkAINDMz/IVzXs0Yc4NmDs7AlrwRxpgNgNUAXuCcVzLGVgIIg+Yu9YQQQshdqOeMdFTJAP7CGNvAGBvCOS8H0BNAPuf8PABwzmWccyWAwQD2aZelA8jF/ybT/p1zXqJ9/iKAVYyxy9BMYm4MQNKg3SMAghhjRgBGA4jjnFcBMADwBWMsGcB30ExP1FL9teVPadueBcClFdsTQgh5hlDPGemQOOeZjLHe0MyL+B5jLBrAoQeoSr9XjAGYzDnPuEe71YyxEwBGApgG4Bvtqn8AKATgD80/NdVNbK7E3f/wGOu1+zvn/NUHiJ8QQsgzhnrOSIfEGHMEoOCc7wOwCZrhyQwAXRhjz2nLmGlP9I8HMF27zB2a3rCmErAoAEsYY0xbNqCZ5r8F8DqAIQCOapdZQNNrpwYwE4Cwie1yAPRijAkYY84A+mqXnwEwiDHmqm23k96wKyGEEHIX6jkjHZUvgE2MMTWAOgAhnPNa7YUB2xhjJtCcb/YCgO0APtMOOSoBzOac12hzMH3vAvgEQBJjTADgOoCxTbT9G4AIAD9yzmu1y7YD+J4xFgxNwlbZxHantHWmAkgDcBEAOOd3GGOzARzQDpcCmnPQMluxPwghhDwjGOf8ccdACCGEEEK0aFiTEEIIIaQDoeSMEEIIIaQDoeSMEEIIIaQDoeSMEEIIIaQDoeSMEEIIIaQDoeSMEEIIIaQDoeSMEEIIIaQD+X8KFpg8+/chFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The **CV method selects** the model returning the **best average score**: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment **many times**, with different data, which would be the **expectation on the best score**?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection $-$ the right way\n",
    "\n",
    "Let's look at the general case of **Model Selection**, i.e. select a variety of models and report their performance.\n",
    "\n",
    "The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$as we have seen $-$ a model can be seen as a configuration which might \"switch\" _on_ or _off_ a specific algorithm.\n",
    "\n",
    "For the sake of simplicity, in this section we will only try to select among different **classifiers** (we forget about all the other processing).\n",
    "\n",
    "<u>Unbiased estimations</u>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ Use a hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ Enter **Nested Cross Validation (NCV)**!\n",
    "\n",
    "<u>How NCV works</u>\n",
    "\n",
    "In the basic CV, we didn't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CV!\n",
    "\n",
    "Now, we can think the NCV as a whole as _the_ **learning method**.\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model and the performance estimations on the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_learning_method.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Important Notice</u>\n",
    "\n",
    "This sounds overinterpreted, but it's not!\n",
    "\n",
    "Notice how the model (configuration) selected by each CV **can be different**!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links before we start:\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to select among models\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.80 | test = 0.93\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 20}), 'scaler__selected_model': ('max', {})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': False, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.819 (+/-0.065)\n",
      "\n",
      "CPU times: user 10.2 s, sys: 48.9 ms, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "0  0.785714  (rf, {'n_estimators': 100})   \n",
       "1  0.857143            (svm, {'C': 0.1})   \n",
       "2  0.928571   (rf, {'n_estimators': 20})   \n",
       "3  0.761905  (rf, {'n_estimators': 100})   \n",
       "4  0.761905            (svm, {'C': 0.1})   \n",
       "\n",
       "                          scaler__selected_model  \n",
       "0   (std, {'with_mean': True, 'with_std': True})  \n",
       "1  (std, {'with_mean': True, 'with_std': False})  \n",
       "2                                      (max, {})  \n",
       "3  (std, {'with_mean': False, 'with_std': True})  \n",
       "4   (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  classifier__selected_model scaler__selected_model\n",
       "2  0.928571  (rf, {'n_estimators': 20})              (max, {})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('rf', {'n_estimators': 20}) ('max', {})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.uniform</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds.\n",
    "\n",
    "**Report the score of the re-trained model on the test set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('max', MaxAbsScaler()),\n",
    "            ('qtt', QuantileTransformer(random_state=0, n_quantiles=10)),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('gpc', GaussianProcessClassifier()),\n",
    "            ('knn', KNeighborsClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'qtt__output_distribution': ['normal', 'uniform'],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'gpc__kernel': [RBF(1.0), RBF(5.0)],\n",
    "            'knn__n_neighbors': randint(3, 20).rvs(size=4),\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.76\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('knn', {'n_neighbors': 9})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('gpc', {'kernel': RBF(length_scale=1)})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.80 | test = 0.90\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('knn', {'n_neighbors': 18})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 5})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 9})}\n",
      "\n",
      "\n",
      "Mean test score: 0.848 (+/-0.053)\n",
      "\n",
      "CPU times: user 36.5 s, sys: 35.6 s, total: 1min 12s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(knn, {'n_neighbors': 9})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=1)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(knn, {'n_neighbors': 18})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 5})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 9})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "0  0.761905   (qtt, {'output_distribution': 'normal'})   \n",
       "1  0.880952   (qtt, {'output_distribution': 'normal'})   \n",
       "2  0.904762   (qtt, {'output_distribution': 'normal'})   \n",
       "3  0.809524  (qtt, {'output_distribution': 'uniform'})   \n",
       "4  0.880952  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "0               (knn, {'n_neighbors': 9})  \n",
       "1  (gpc, {'kernel': RBF(length_scale=1)})  \n",
       "2              (knn, {'n_neighbors': 18})  \n",
       "3               (knn, {'n_neighbors': 5})  \n",
       "4               (knn, {'n_neighbors': 9})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(knn, {'n_neighbors': 18})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                    scaler__selected_model  \\\n",
       "2  0.904762  (qtt, {'output_distribution': 'normal'})   \n",
       "\n",
       "   classifier__selected_model  \n",
       "2  (knn, {'n_neighbors': 18})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('qtt', {'output_distribution': 'normal'}) ('knn', {'n_neighbors': 18})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.88%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'automl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28530/1528610069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msprint_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Predicting labels of test set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'automl' is not defined"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
