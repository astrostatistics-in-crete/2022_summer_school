{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "\"**Tuning**\" refers to the procedure of selecting the best hyper-parameters for a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration (mean CV score = 0.862):\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 6, 'RFC__n_estimators': 100}\n",
      "CPU times: user 544 ms, sys: 60.7 ms, total: 604 ms\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration (mean CV score = %0.3f):\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the assessment method is _wrong_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The CV method selects the model returning the best average score: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment many times, with different data, which would be the expectation on the best score?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.82%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection $-$ the right way\n",
    "\n",
    "Let's look at the general case of **Model Selection**, i.e. select a variety of models and report their performance.\n",
    "\n",
    "The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$as we have seen $-$ a model can be seen as a configuration which might \"switch\" _on_ or _off_ a specific algorithm.\n",
    "\n",
    "For the sake of simplicity, in this section we will only try to select among different **classifiers** (we forget about all the other processing).\n",
    "\n",
    "<u>Unbiased estimations</u>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ Use a hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ Enter **Nested Cross Validation (NCV)**!\n",
    "\n",
    "<u>How NCV works</u>\n",
    "\n",
    "In the basic CV, we didn't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CV!\n",
    "\n",
    "Now, we can think the NCV as a whole as _the_ **learning method**.\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model and the performance estimations on the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_learning_method.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Important Notice</u>\n",
    "\n",
    "This sounds overinterpreted, but it's not!\n",
    "\n",
    "Notice how the model (configuration) selected by each CV **can be different**!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links before we start:\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to select among models\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.81\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('max', {})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 1.0}), 'scaler__selected_model': ('std', {'with_mean': False, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.80 | test = 0.90\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': False, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.824 (+/-0.051)\n",
      "\n",
      "CPU times: user 9.71 s, sys: 79 ms, total: 9.79 s\n",
      "Wall time: 9.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 1.0})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "0  0.809524  (rf, {'n_estimators': 100})   \n",
       "1  0.857143            (svm, {'C': 1.0})   \n",
       "2  0.904762  (rf, {'n_estimators': 100})   \n",
       "3  0.785714            (svm, {'C': 0.1})   \n",
       "4  0.761905            (svm, {'C': 0.1})   \n",
       "\n",
       "                           scaler__selected_model  \n",
       "0                                       (max, {})  \n",
       "1  (std, {'with_mean': False, 'with_std': False})  \n",
       "2  (std, {'with_mean': False, 'with_std': False})  \n",
       "3    (std, {'with_mean': True, 'with_std': True})  \n",
       "4    (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "2  0.904762  (rf, {'n_estimators': 100})   \n",
       "\n",
       "                           scaler__selected_model  \n",
       "2  (std, {'with_mean': False, 'with_std': False})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('rf', {'n_estimators': 100})\n",
      "  ('std', {'with_mean': False, 'with_std': False})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.84%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.uniform</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds.\n",
    "\n",
    "**Report the score of the re-trained model on the test set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('max', MaxAbsScaler()),\n",
    "            ('qtt', QuantileTransformer(random_state=0, n_quantiles=10)),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('gpc', GaussianProcessClassifier()),\n",
    "            ('knn', KNeighborsClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'qtt__output_distribution': ['normal', 'uniform'],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'gpc__kernel': [RBF(1.0), RBF(5.0)],\n",
    "            'knn__n_neighbors': randint(3, 20).rvs(size=4),\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.88 | test = 0.83\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 16})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('gpc', {'kernel': RBF(length_scale=1)})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 13})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.86\n",
      "\tSelected config: {'scaler__selected_model': ('max', {}), 'classifier__selected_model': ('knn', {'n_neighbors': 14})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.84 | test = 0.81\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('knn', {'n_neighbors': 6})}\n",
      "\n",
      "\n",
      "Mean test score: 0.852 (+/-0.028)\n",
      "\n",
      "CPU times: user 13.3 s, sys: 10.9 s, total: 24.1 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 16})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=1)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 13})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>(knn, {'n_neighbors': 14})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(knn, {'n_neighbors': 6})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "0  0.833333  (qtt, {'output_distribution': 'uniform'})   \n",
       "1  0.880952  (qtt, {'output_distribution': 'uniform'})   \n",
       "2  0.880952  (qtt, {'output_distribution': 'uniform'})   \n",
       "3  0.857143                                  (max, {})   \n",
       "4  0.809524   (qtt, {'output_distribution': 'normal'})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "0              (knn, {'n_neighbors': 16})  \n",
       "1  (gpc, {'kernel': RBF(length_scale=1)})  \n",
       "2              (knn, {'n_neighbors': 13})  \n",
       "3              (knn, {'n_neighbors': 14})  \n",
       "4               (knn, {'n_neighbors': 6})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=1)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 13})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "1  0.880952  (qtt, {'output_distribution': 'uniform'})   \n",
       "2  0.880952  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "1  (gpc, {'kernel': RBF(length_scale=1)})  \n",
       "2              (knn, {'n_neighbors': 13})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('qtt', {'output_distribution': 'uniform'})\n",
      "  ('gpc', {'kernel': RBF(length_scale=1)})]\n",
      " [('qtt', {'output_distribution': 'uniform'})\n",
      "  ('knn', {'n_neighbors': 13})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 1.44 s, total: 53.5 s\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, per_run_time_limit=12,\n",
       "                      time_left_for_this_task=120)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: cb5ae8d1-021c-11ed-b04a-1002b5312d0b\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.928571\n",
      "  Number of target algorithm runs: 54\n",
      "  Number of successful target algorithm runs: 54\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selected model ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{43: {'model_id': 43,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0714285714285714,\n",
       "  'ensemble_weight': 1.0,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f2c92636b80>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f2ce5842b80>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f2ce5842370>,\n",
       "  'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
       "                early_stopping=True, hidden_layer_sizes=(112, 112),\n",
       "                learning_rate_init=0.00020139694272470796, max_iter=32,\n",
       "                n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"data_preprocessing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0,\n",
       "                                                    transformers=[('numerical_transformer',\n",
       "                                                                   NumericalPreprocessingPipeline(config=Configuration:\n",
       "   imputation:strategy, Value: 'median'\n",
       "   rescaling:__choice__, Value: 'standardize'\n",
       " , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Num...\n",
       "                       'categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "                       'numerical_transformer:imputation:strategy': 'median',\n",
       "                       'numerical_transformer:rescaling:__choice__': 'standardize'},\n",
       "               feat_type={0: 'numerical', 1: 'numerical', 2: 'numerical',\n",
       "                          3: 'numerical', 4: 'numerical', 5: 'numerical',\n",
       "                          6: 'numerical', 7: 'numerical', 8: 'numerical',\n",
       "                          9: 'numerical'},\n",
       "               init_params={}),\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"balancing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'strategy': 'weighting', 'random_state': 1, 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"feature_preprocessor\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    random_state=1),\n",
       " 'new_params': {'degree': 2,\n",
       "  'include_bias': 'True',\n",
       "  'interaction_only': 'False',\n",
       "  'random_state': 1},\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
