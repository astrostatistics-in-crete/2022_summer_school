{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning (low sample size)\n",
    "\n",
    "**Hyperparameter tuning** == **select** the best hyperparameters of a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation with Tuning (CVT)** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=1000>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 8, 'RFC__n_estimators': 100}\n",
      "\n",
      "Best configuration: mean CV score = 0.871\n",
      "\n",
      "CPU times: user 517 ms, sys: 54.7 ms, total: 572 ms\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(\"\\nBest configuration: mean CV score = %0.3f\\n\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the assessment method is _wrong_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The **CVT method selects** the model returning the **best average score**: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment **many times**, with different data, which would be the **expectation on the best score**?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and assessment $-$ the right way\n",
    "\n",
    "Let's formulate the problem in the general case of **Model Selection**, i.e. select among a variety of models and report their performance.\n",
    "\n",
    "_NOTE: The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$ as we have seen $-$ a model can be seen as a configuration which might \"switch\" on or off a specific algorithm._\n",
    "\n",
    "<font size=3><u>**Unbiased estimations**</u><font>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ CV + hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ CV + **Nested Cross Validation (NCV)**!\n",
    "\n",
    "> CV $\\leftarrow$ gives us the **best model**\n",
    "\n",
    "> NCV $\\leftarrow$ gives us **performance assessment** of our CV method\n",
    "\n",
    "<font size=3><u>**How NCV works**</u><font>\n",
    "\n",
    "First of all, let's think of CVT as a **learning method**:\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model\n",
    "\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CVT_learning_method.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Cross Validation with Tuning as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Issue:</u> In CVT, we don't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CVT!\n",
    "\n",
    "The **performance estimate** will be $\\rightarrow$ the **average performance over the outer loop**.\n",
    "\n",
    "- - -\n",
    "\n",
    "<font size=3><u>**Important**</u><font>\n",
    "\n",
    "Notice how the model (configuration) selected by each CVT **can be different**!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**Final model**</u><font>\n",
    "\n",
    "    What is the final model? The one with the best score in outer loop?\n",
    "\n",
    "NO $\\rightarrow$ NCV only assesses the **performance of our learning method** (CVT).    \n",
    "\n",
    "If you want the best model, just run **CVT on all the data**.\n",
    "    \n",
    "See discussion [here](https://stats.stackexchange.com/questions/65128/nested-cross-validation-for-model-selection).\n",
    "\n",
    "<font size=3><u>**Useful links**</u><font>\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to assess our learning method\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('max', {})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.79 | test = 0.88\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.819 (+/-0.044)\n",
      "\n",
      "CPU times: user 9.61 s, sys: 86.2 ms, total: 9.69 s\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(max, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "0  0.809524  (rf, {'n_estimators': 100})   \n",
       "1  0.857143            (svm, {'C': 0.1})   \n",
       "2  0.880952  (rf, {'n_estimators': 100})   \n",
       "3  0.785714            (svm, {'C': 0.1})   \n",
       "4  0.761905            (svm, {'C': 0.1})   \n",
       "\n",
       "                          scaler__selected_model  \n",
       "0                                      (max, {})  \n",
       "1  (std, {'with_mean': True, 'with_std': False})  \n",
       "2   (std, {'with_mean': True, 'with_std': True})  \n",
       "3   (std, {'with_mean': True, 'with_std': True})  \n",
       "4   (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.uniform</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    # edit here ...\n",
    "    \n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the rest of the code from the previous Section :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1.2: Find the final model via an additional CVT\n",
    "\n",
    "And report the score on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ctrl+C Ctrl+V is your friend.\n",
    "#\n",
    "# If you use OSX ... oh well, not my fault."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.3 s, sys: 1.09 s, total: 53.3 s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, per_run_time_limit=12,\n",
       "                      time_left_for_this_task=120)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 789bbba3-02fa-11ed-9a7d-1002b5312d0b\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.928571\n",
      "  Number of target algorithm runs: 54\n",
      "  Number of successful target algorithm runs: 54\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selected model ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{43: {'model_id': 43,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0714285714285714,\n",
       "  'ensemble_weight': 1.0,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fd2f259adf0>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fd2f25d5850>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fd341128d30>,\n",
       "  'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
       "                early_stopping=True, hidden_layer_sizes=(112, 112),\n",
       "                learning_rate_init=0.00020139694272470796, max_iter=32,\n",
       "                n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"data_preprocessing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0,\n",
       "                                                    transformers=[('numerical_transformer',\n",
       "                                                                   NumericalPreprocessingPipeline(config=Configuration:\n",
       "   imputation:strategy, Value: 'median'\n",
       "   rescaling:__choice__, Value: 'standardize'\n",
       " , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Num...\n",
       "                       'categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "                       'numerical_transformer:imputation:strategy': 'median',\n",
       "                       'numerical_transformer:rescaling:__choice__': 'standardize'},\n",
       "               feat_type={0: 'numerical', 1: 'numerical', 2: 'numerical',\n",
       "                          3: 'numerical', 4: 'numerical', 5: 'numerical',\n",
       "                          6: 'numerical', 7: 'numerical', 8: 'numerical',\n",
       "                          9: 'numerical'},\n",
       "               init_params={}),\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"balancing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'strategy': 'weighting', 'random_state': 1, 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"feature_preprocessor\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    random_state=1),\n",
       " 'new_params': {'degree': 2,\n",
       "  'include_bias': 'True',\n",
       "  'interaction_only': 'False',\n",
       "  'random_state': 1},\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.583px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
