{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning (low sample size)\n",
    "\n",
    "**Hyperparameter tuning** == **select** the best hyperparameters of a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's take the Random Forests **classifier** (RF**C**). Its <code>sklearn</code> implementation has 10 tunable hyperparameters (plus a few more that are related to the computational execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;PCA&#x27;, PCA()), (&#x27;RFC&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;PCA&#x27;, PCA()), (&#x27;RFC&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=1000>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 8, 'RFC__n_estimators': 100}\n",
      "\n",
      "Best configuration: mean CV score = 0.876\n",
      "\n",
      "CPU times: user 422 ms, sys: 18.8 ms, total: 440 ms\n",
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(\"\\nBest configuration: mean CV score = %0.3f\\n\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the assessment method is _wrong_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The **CV method selects** the model returning the **best average score**: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment **many times**, with different data, which would be the **expectation on the best score**?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.81%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection $-$ the right way\n",
    "\n",
    "Let's look at the general case of **Model Selection**, i.e. select a variety of models and report their performance.\n",
    "\n",
    "The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$as we have seen $-$ a model can be seen as a configuration which might \"switch\" _on_ or _off_ a specific algorithm.\n",
    "\n",
    "For the sake of simplicity, in this section we will only try to select among different **classifiers** (we forget about all the other processing).\n",
    "\n",
    "<u>Unbiased estimations</u>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ Use a hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ Enter **Nested Cross Validation (NCV)**!\n",
    "\n",
    "<u>How NCV works</u>\n",
    "\n",
    "In the basic CV, we didn't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CV!\n",
    "\n",
    "Now, we can think the NCV as a whole as _the_ **learning method**.\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model and the performance estimations on the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_learning_method.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Important Notice</u>\n",
    "\n",
    "This sounds overinterpreted, but it's not!\n",
    "\n",
    "Notice how the model (configuration) selected by each CV **can be different**!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links before we start:\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to select among models\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.87 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 20}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 1.0}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.80 | test = 0.88\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 20}), 'scaler__selected_model': ('std', {'with_mean': False, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.829 (+/-0.046)\n",
      "\n",
      "CPU times: user 11.3 s, sys: 78.6 ms, total: 11.4 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 1.0})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  classifier__selected_model  \\\n",
       "0  0.857143  (rf, {'n_estimators': 20})   \n",
       "1  0.857143           (svm, {'C': 1.0})   \n",
       "2  0.880952  (rf, {'n_estimators': 20})   \n",
       "3  0.785714           (svm, {'C': 0.1})   \n",
       "4  0.761905           (svm, {'C': 0.1})   \n",
       "\n",
       "                           scaler__selected_model  \n",
       "0   (std, {'with_mean': True, 'with_std': False})  \n",
       "1   (std, {'with_mean': True, 'with_std': False})  \n",
       "2  (std, {'with_mean': False, 'with_std': False})  \n",
       "3    (std, {'with_mean': True, 'with_std': True})  \n",
       "4    (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  classifier__selected_model  \\\n",
       "2  0.880952  (rf, {'n_estimators': 20})   \n",
       "\n",
       "                           scaler__selected_model  \n",
       "2  (std, {'with_mean': False, 'with_std': False})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('rf', {'n_estimators': 20})\n",
      "  ('std', {'with_mean': False, 'with_std': False})]]\n"
     ]
    }
   ],
   "source": [
    "# Picking best configuration\n",
    "# IMPORTANT: Pick min/max score if the selection minimizes/maximises the score!\n",
    "#            e.g., when using -log(score)\n",
    "\n",
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)\n",
    "print('Best configuration:')\n",
    "df_best = df_outer_scores[df_outer_scores['score'] == df_outer_scores['score'].max()]\n",
    "display(df_best)\n",
    "\n",
    "best_config = df_best.drop ('score', axis=1).values\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Retraining best configuration on all training data\n",
    "\n",
    "# Picking best-fit model object:\n",
    "idx_best = df_best.index.values[0]\n",
    "model_NCV = best_inner_models[idx_best]\n",
    "\n",
    "model_NCV.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.81%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Predicting labels of test set:\n",
    "yhat_test = model_NCV.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.uniform</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds.\n",
    "\n",
    "**Report the score of the re-trained model on the test set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    # edit here ...\n",
    "    \n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the rest of the code from the previous Section :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 1.03 s, total: 54.1 s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, per_run_time_limit=12,\n",
       "                      time_left_for_this_task=120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 617f6429-021c-11ed-ac8c-1002b5312d0b\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.928571\n",
      "  Number of target algorithm runs: 53\n",
      "  Number of successful target algorithm runs: 53\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selected model ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{43: {'model_id': 43,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0714285714285714,\n",
       "  'ensemble_weight': 1.0,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f8fa151dfa0>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f8fa10e0850>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f8fa10e0880>,\n",
       "  'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
       "                early_stopping=True, hidden_layer_sizes=(112, 112),\n",
       "                learning_rate_init=0.00020139694272470796, max_iter=32,\n",
       "                n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"data_preprocessing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0,\n",
       "                                                    transformers=[('numerical_transformer',\n",
       "                                                                   NumericalPreprocessingPipeline(config=Configuration:\n",
       "   imputation:strategy, Value: 'median'\n",
       "   rescaling:__choice__, Value: 'standardize'\n",
       " , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Num...\n",
       "                       'categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "                       'numerical_transformer:imputation:strategy': 'median',\n",
       "                       'numerical_transformer:rescaling:__choice__': 'standardize'},\n",
       "               feat_type={0: 'numerical', 1: 'numerical', 2: 'numerical',\n",
       "                          3: 'numerical', 4: 'numerical', 5: 'numerical',\n",
       "                          6: 'numerical', 7: 'numerical', 8: 'numerical',\n",
       "                          9: 'numerical'},\n",
       "               init_params={}),\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"balancing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'strategy': 'weighting', 'random_state': 1, 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"feature_preprocessor\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    random_state=1),\n",
       " 'new_params': {'degree': 2,\n",
       "  'include_bias': 'True',\n",
       "  'interaction_only': 'False',\n",
       "  'random_state': 1},\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
